{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train_vec = np.load(\"wmt_data/X_train.npy\")\n",
    "X_eval_vec = np.load(\"wmt_data/X_eval.npy\")\n",
    "X_test_vec = np.load(\"wmt_data/X_test.npy\")\n",
    "\n",
    "dataset = DatasetDict.load_from_disk(\"wmt_data/full_dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "SVR()",
      "text/html": "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVR()\n",
    "n_samples = 5000\n",
    "clf.fit(X_train_vec[:n_samples], dataset['train']['label'][:n_samples])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.2628466066157682\n",
      "MSE eval: 0.2963647795068554\n"
     ]
    }
   ],
   "source": [
    "labels_pred = clf.predict(X_train_vec[:n_samples])\n",
    "print(\"MSE train:\", mean_squared_error(dataset['train']['label'][:n_samples], labels_pred))\n",
    "\n",
    "labels_pred_eval = clf.predict(X_eval_vec)\n",
    "print(\"MSE eval:\", mean_squared_error(dataset['eval']['label'], labels_pred_eval))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1112], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.1507], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.0709], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([0.0452], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def svr_metric(out, ref):\n",
    "    vec_out = sentence_model.encode(out)\n",
    "    vec_ref = sentence_model.encode(ref)\n",
    "    return clf.predict([np.concatenate([vec_ref, vec_out])])\n",
    "\n",
    "def nn_metric(out, ref):\n",
    "    return model(out, ref)\n",
    "\n",
    "scorer = nn_metric\n",
    "\n",
    "print(scorer(\"It's rather hot in here.\", \"It's rather hot in here.\"))\n",
    "print(scorer(\"It's rather hot in here.\", \"It's rather warm in here.\"))\n",
    "print(scorer(\"It's rather hot in here.\", \"It's rather not hot in here.\"))\n",
    "print(scorer(\"Luckily, people are interested in borrowing skis.\", \"Fortunately, there is interest in ski rental.\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"wmt_data_bleurt/svr_5k.pkl\", 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "with open(\"wmt_data/svr_10k.pkl\", 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 4040: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m     vec_ref \u001B[38;5;241m=\u001B[39m sentence_model\u001B[38;5;241m.\u001B[39mencode(ref)\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m clf\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39mconcatenate([vec_ref, vec_out], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m---> 10\u001B[0m evs \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEvalSet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mwmt20\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43men-de\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m scores \u001B[38;5;241m=\u001B[39m {level: {} \u001B[38;5;28;01mfor\u001B[39;00m level \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msys\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdoc\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseg\u001B[39m\u001B[38;5;124m'\u001B[39m]}\n\u001B[0;32m     12\u001B[0m ref \u001B[38;5;241m=\u001B[39m evs\u001B[38;5;241m.\u001B[39mall_refs[evs\u001B[38;5;241m.\u001B[39mstd_ref]\n",
      "File \u001B[1;32mD:\\Users\\Miriam Anschütz\\Documents\\workspaces\\PyCharm projects\\negation_aware_evaluation\\mtMetricsEval\\mt_metrics_eval\\data.py:77\u001B[0m, in \u001B[0;36mEvalSet.__init__\u001B[1;34m(self, name, lp, read_stored_metric_scores, info, path, strict)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(info)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_std_human_scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mstd_gold\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ReadDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_stored_metric_scores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# Check compatibility between info and data read in.\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# No checks for primary metrics because there are no hard requirements:\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;66;03m# no metrics for this lp need to be primary.\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstd_ref \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mref_names:\n",
      "File \u001B[1;32mD:\\Users\\Miriam Anschütz\\Documents\\workspaces\\PyCharm projects\\negation_aware_evaluation\\mtMetricsEval\\mt_metrics_eval\\data.py:382\u001B[0m, in \u001B[0;36mEvalSet._ReadDataset\u001B[1;34m(self, name, lp, read_stored_metric_scores, path, strict)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m glob\u001B[38;5;241m.\u001B[39mglob(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(d, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msystem-outputs\u001B[39m\u001B[38;5;124m'\u001B[39m, lp, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*.txt\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m    381\u001B[0m   sysname \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(filename)[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.txt\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m--> 382\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sys_outputs[sysname] \u001B[38;5;241m=\u001B[39m \u001B[43m_ReadTextFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    383\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m sysname \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_all_refs:\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_human_sys_names\u001B[38;5;241m.\u001B[39madd(sysname)\n",
      "File \u001B[1;32mD:\\Users\\Miriam Anschütz\\Documents\\workspaces\\PyCharm projects\\negation_aware_evaluation\\mtMetricsEval\\mt_metrics_eval\\data.py:479\u001B[0m, in \u001B[0;36m_ReadTextFile\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ReadTextFile\u001B[39m(filename):\n\u001B[0;32m    478\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 479\u001B[0m     lines \u001B[38;5;241m=\u001B[39m [line\u001B[38;5;241m.\u001B[39mrstrip() \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f]\n\u001B[0;32m    480\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m lines\n",
      "File \u001B[1;32mD:\\Users\\Miriam Anschütz\\Documents\\workspaces\\PyCharm projects\\negation_aware_evaluation\\mtMetricsEval\\mt_metrics_eval\\data.py:479\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ReadTextFile\u001B[39m(filename):\n\u001B[0;32m    478\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filename) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 479\u001B[0m     lines \u001B[38;5;241m=\u001B[39m [line\u001B[38;5;241m.\u001B[39mrstrip() \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f]\n\u001B[0;32m    480\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m lines\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:23\u001B[0m, in \u001B[0;36mIncrementalDecoder.decode\u001B[1;34m(self, input, final)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, final\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcodecs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcharmap_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdecoding_table\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m: 'charmap' codec can't decode byte 0x81 in position 4040: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "#import mtMetricsEval.mt_metrics_eval as mte\n",
    "#import mtMetricsEval.mt_metrics_eval.data\n",
    "from mtMetricsEval.mt_metrics_eval import data\n",
    "\n",
    "evs = data.EvalSet('wmt20', 'en-de')\n",
    "scores = {level: {} for level in ['sys', 'doc', 'seg']}\n",
    "ref = evs.all_refs[evs.std_ref]\n",
    "for s, out in evs.sys_outputs.items():\n",
    "  scores['sys'][s] = [svr_metric(out, ref)]\n",
    "  scores['doc'][s] = [svr_metric(out[b:e], ref[b:e]) for b, e in evs.docs.values()]\n",
    "  scores['seg'][s] = [svr_metric([o], [r]) for o, r in zip(out, ref)]\n",
    "\n",
    "# Official WMT correlations.\n",
    "for level in 'sys', 'doc', 'seg':\n",
    "  gold_scores = evs.Scores(level, evs.StdHumanScoreName(level))\n",
    "  sys_names = set(gold_scores) - evs.human_sys_names\n",
    "  corr = evs.Correlation(gold_scores, scores[level], sys_names)\n",
    "  print(f'{level}: Pearson={corr.Pearson()[0]:f}, '\n",
    "        f'Kendall-like={corr.KendallLike()[0]:f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"mtMetricsEval\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NLI tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import math\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datasets import DatasetDict, Dataset\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "timestamp = \"2023-02-17_15-02-13\"\n",
    "project_base_path = Path(\"Guided Research WS22\")\n",
    "negation_dataset = project_base_path / \"data/negation_dataset_labeled.tsv\"\n",
    "\n",
    "base_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "output_model_name = f\"{base_model.split('/')[1]}-negation\"  # TODO.\n",
    "model_save_path = str(project_base_path / f\"finetuned-models/{timestamp}/{output_model_name}\")\n",
    "\n",
    "model_name = model_save_path\n",
    "train_batch_size = 2          #The larger you select this, the better the results (usually). But it requires more GPU memory\n",
    "max_seq_length = 75\n",
    "num_epochs = 1\n",
    "data_save_path = \"wmt_data_augmented\"\n",
    "\n",
    "model_save_path = 'output/nli_model_regression'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:17:51 - Use pytorch device: cuda\n",
      "2023-03-31 14:17:51 - Loaded models and data\n"
     ]
    }
   ],
   "source": [
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode='mean')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "dataset = DatasetDict.load_from_disk(data_save_path)\n",
    "logging.info(\"Loaded models and data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 387264/387264 [00:30<00:00, 12807.06it/s]\n",
      "100%|██████████| 48408/48408 [00:03<00:00, 13926.40it/s]\n",
      "100%|██████████| 48408/48408 [00:03<00:00, 13732.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def dataset_to_InputExample(dataset: Dataset, ref_column: str, cand_column: str, lab_column:str) -> list[InputExample] :\n",
    "    return [\n",
    "        InputExample(i, texts=[x[ref_column], x[cand_column]], label=x[lab_column])\n",
    "        for i, x in tqdm(enumerate(dataset), total=len(dataset))\n",
    "    ]\n",
    "\n",
    "train_samples = dataset_to_InputExample(dataset['train'], 'reference', 'candidate', 'score')[:1000]\n",
    "dev_samples = dataset_to_InputExample(dataset['eval'], 'reference', 'candidate', 'score')\n",
    "test_samples = dataset_to_InputExample(dataset['test'], 'reference', 'candidate', 'score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:21:45 - Train samples: 1000\n",
      "2023-03-31 14:21:45 - Softmax loss: #Vectors concatenated: 3\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Train samples: {}\".format(len(train_samples)))\n",
    "# Special data loader that avoid duplicates within a batch\n",
    "train_dataloader = datasets.NoDuplicatesDataLoader(train_samples, batch_size=train_batch_size)\n",
    "# Our training loss\n",
    "#train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "train_loss = losses.SoftmaxLoss(model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=1, loss_fct=torch.nn.MSELoss())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:21:50 - Warmup-steps: 50\n"
     ]
    }
   ],
   "source": [
    "dev_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(dev_samples, batch_size=train_batch_size, name='sts-dev')\n",
    "\n",
    "# Configure the training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "998d926dc04b41c2b9e87e75de835431"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Iteration:   0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "908f11b6f4914a21a4fb1ce06eb1c92c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:23:09 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 250 steps:\n",
      "2023-03-31 14:37:58 - Cosine-Similarity :\tPearson: 0.4656\tSpearman: 0.5695\n",
      "2023-03-31 14:37:58 - Manhattan-Distance:\tPearson: 0.5200\tSpearman: 0.5620\n",
      "2023-03-31 14:37:58 - Euclidean-Distance:\tPearson: 0.5207\tSpearman: 0.5626\n",
      "2023-03-31 14:37:58 - Dot-Product-Similarity:\tPearson: 0.4065\tSpearman: 0.4219\n",
      "2023-03-31 14:37:58 - Save model to output/nli_model_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:39:17 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset in epoch 0 after 500 steps:\n",
      "2023-03-31 14:54:12 - Cosine-Similarity :\tPearson: 0.4735\tSpearman: 0.5747\n",
      "2023-03-31 14:54:12 - Manhattan-Distance:\tPearson: 0.5165\tSpearman: 0.5599\n",
      "2023-03-31 14:54:12 - Euclidean-Distance:\tPearson: 0.5172\tSpearman: 0.5605\n",
      "2023-03-31 14:54:12 - Dot-Product-Similarity:\tPearson: 0.3775\tSpearman: 0.3937\n",
      "2023-03-31 14:54:12 - Save model to output/nli_model_regression\n",
      "2023-03-31 14:54:13 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2023-03-31 15:09:08 - Cosine-Similarity :\tPearson: 0.4735\tSpearman: 0.5747\n",
      "2023-03-31 15:09:08 - Manhattan-Distance:\tPearson: 0.5165\tSpearman: 0.5599\n",
      "2023-03-31 15:09:08 - Euclidean-Distance:\tPearson: 0.5172\tSpearman: 0.5605\n",
      "2023-03-31 15:09:08 - Dot-Product-Similarity:\tPearson: 0.3775\tSpearman: 0.3937\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=dev_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=int(len(train_dataloader)*0.5),\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path,\n",
    "          use_amp=True          #Set to True, if your GPU supports FP16 operations\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/3125 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b6f93678f4347128e85f7bce0a3391a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'InputExample' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_samples\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:161\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[1;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m start_index \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(sentences), batch_size, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBatches\u001B[39m\u001B[38;5;124m\"\u001B[39m, disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m show_progress_bar):\n\u001B[0;32m    160\u001B[0m     sentences_batch \u001B[38;5;241m=\u001B[39m sentences_sorted[start_index:start_index\u001B[38;5;241m+\u001B[39mbatch_size]\n\u001B[1;32m--> 161\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentences_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m     features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:319\u001B[0m, in \u001B[0;36mSentenceTransformer.tokenize\u001B[1;34m(self, texts)\u001B[0m\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtokenize\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts: Union[List[\u001B[38;5;28mstr\u001B[39m], List[Dict], List[Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]]]):\n\u001B[0;32m    316\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    317\u001B[0m \u001B[38;5;124;03m    Tokenizes the texts\u001B[39;00m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 319\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_first_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:102\u001B[0m, in \u001B[0;36mTransformer.tokenize\u001B[1;34m(self, texts)\u001B[0m\n\u001B[0;32m    100\u001B[0m batch1, batch2 \u001B[38;5;241m=\u001B[39m [], []\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text_tuple \u001B[38;5;129;01min\u001B[39;00m texts:\n\u001B[1;32m--> 102\u001B[0m     batch1\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtext_tuple\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m    103\u001B[0m     batch2\u001B[38;5;241m.\u001B[39mappend(text_tuple[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    104\u001B[0m to_tokenize \u001B[38;5;241m=\u001B[39m [batch1, batch2]\n",
      "\u001B[1;31mTypeError\u001B[0m: 'InputExample' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.encode(train_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:20:28 - Load pretrained SentenceTransformer: output/nli_model\n",
      "2023-03-31 11:20:32 - Use pytorch device: cuda\n",
      "2023-03-31 11:20:32 - EmbeddingSimilarityEvaluator: Evaluating the model on sts-test dataset:\n",
      "2023-03-31 11:36:34 - Cosine-Similarity :\tPearson: 0.4482\tSpearman: 0.5639\n",
      "2023-03-31 11:36:34 - Manhattan-Distance:\tPearson: 0.5110\tSpearman: 0.5602\n",
      "2023-03-31 11:36:34 - Euclidean-Distance:\tPearson: 0.5111\tSpearman: 0.5602\n",
      "2023-03-31 11:36:34 - Dot-Product-Similarity:\tPearson: 0.3696\tSpearman: 0.3909\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.5638637912636975"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer(model_save_path)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, batch_size=train_batch_size, name='sts-test')\n",
    "test_evaluator(model, output_path=model_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "SentenceTransformer(\n  (0): Transformer({'max_seq_length': 75, 'do_lower_case': False}) with Transformer model: MPNetModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}