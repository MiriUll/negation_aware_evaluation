{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Transformer score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "timestamp = \"2023-02-17_15-02-13\"\n",
    "project_base_path = Path(\"Guided Research WS22\")\n",
    "negation_dataset = project_base_path / \"data/negation_dataset_labeled.tsv\"\n",
    "\n",
    "\n",
    "base_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "output_model_name = f\"{base_model.split('/')[1]}-negation\"  # TODO.\n",
    "model_save_path = str(project_base_path / f\"finetuned-models/{timestamp}/{output_model_name}\")\n",
    "model_save_path_wmt = \"finetuned-models/all-mpnet-base-v2-negation_wmt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "finetuned_model = SentenceTransformer(model_save_path, device=device)\n",
    "finetuned_model_wmt = SentenceTransformer(model_save_path_wmt, device=device)\n",
    "base_model = SentenceTransformer(base_model, device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's rather hot in here.\n",
      "It's rather cold in here.\n",
      "Base tensor([0.6409])\n",
      "FT tensor([0.3928])\n",
      "FT WMT tensor([0.3756])\n",
      "This is a red cat with a hat.\n",
      "This isn't a red cat with a hat.\n",
      "Base tensor([0.8470])\n",
      "FT tensor([0.5079])\n",
      "FT WMT tensor([0.3306])\n",
      "This is a red cat with a hat.\n",
      "This is not a red cat with a hat.\n",
      "Base tensor([0.8495])\n",
      "FT tensor([0.4682])\n",
      "FT WMT tensor([0.3956])\n",
      "Today is a beautiful day.\n",
      "Today is a wonderful day.\n",
      "Base tensor([0.8489])\n",
      "FT tensor([0.8935])\n",
      "FT WMT tensor([0.9358])\n",
      "Today is a beautiful day.\n",
      ".\n",
      "Base tensor([0.1430])\n",
      "FT tensor([0.1549])\n",
      "FT WMT tensor([0.1635])\n",
      "I have the time to do this.\n",
      "I do not have the time to do this.\n",
      "Base tensor([0.5700])\n",
      "FT tensor([0.3170])\n",
      "FT WMT tensor([0.3868])\n",
      "I have the time to do this.\n",
      "I have no time to do this.\n",
      "Base tensor([0.5427])\n",
      "FT tensor([0.3020])\n",
      "FT WMT tensor([0.3731])\n"
     ]
    }
   ],
   "source": [
    "def cos_score(reference: str, candidate: str, model:SentenceTransformer) -> float:\n",
    "    emb_ref = model.encode(reference)\n",
    "    emb_cand = model.encode(candidate)\n",
    "    return util.cos_sim(emb_ref, emb_cand).item()\n",
    "\n",
    "def cos_score_batched(references: list, candidates: list, model: SentenceTransformer, batch_size=8) -> torch.Tensor:\n",
    "    assert len(references) == len(candidates), \"Number of references and candidates must be equal\"\n",
    "    emb_ref = model.encode(references, batch_size=batch_size)\n",
    "    emb_cand = model.encode(candidates, batch_size=batch_size)\n",
    "    return torch.diag(util.cos_sim(emb_ref, emb_cand))\n",
    "\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\"]\n",
    "\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\",\n",
    "          \"This is a red cat with a hat.\", \"Today is a beautiful day.\", \"Today is a beautiful day.\",\n",
    "          \"I have the time to do this.\", \"I have the time to do this.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\", \".\",\n",
    "          \"I do not have the time to do this.\", \"I have no time to do this.\"]\n",
    "#print(\"Base model score\", cos_score(sents1[0], sents2[0], base_model))\n",
    "#print(\"Fine-tuned model score\", cos_score(sents1[0], sents2[0], finetuned_model))\n",
    "#print(\"\\n\")\n",
    "#print(\"Base model score\", cos_score_batched(sents1, sents2, base_model))\n",
    "#print(\"Fine-tuned model score\", cos_score_batched(sents1, sents2, finetuned_model))\n",
    "#print(\"WMT Fine-tuned model score\", cos_score_batched(sents1, sents2, finetuned_model_wmt))\n",
    "\n",
    "\n",
    "#sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\", \"This is a red cat with a hat.\", \"Today is a beautiful day.\", \"You are fat.\"]\n",
    "#sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\", \"You are not thin.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(\"Base\", cos_score_batched([s1], [s2], base_model))\n",
    "    print(\"FT\", cos_score_batched([s1], [s2], finetuned_model))\n",
    "    print(\"FT WMT\", cos_score_batched([s1], [s2], finetuned_model_wmt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NegBERT score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"joey234/cuenb\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"BERTNOT/output\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"joey234/cuenb\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"BERTNOT/output_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 11, 50265])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = tokenizer(\"This is a red cat with a hat.\", return_tensors='pt')\n",
    "model(**tok).logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['<s>This is a red cat with a hat.</s>']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(tok['input_ids'], skip_special_tokens=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's rather hot in here.\n",
      "It's rather cold in here.\n",
      "tensor([0.9931], grad_fn=<DiagBackward0>)\n",
      "This is a red cat with a hat.\n",
      "This isn't a red cat with a hat.\n",
      "tensor([0.8886], grad_fn=<DiagBackward0>)\n",
      "This is a red cat with a hat.\n",
      "This is not a red cat with a hat.\n",
      "tensor([0.7516], grad_fn=<DiagBackward0>)\n",
      "Today is a beautiful day.\n",
      "Today is a wonderful day.\n",
      "tensor([0.9886], grad_fn=<DiagBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def cos_score_batched(references: list, candidates: list, model: AutoModelForMaskedLM, batch_size=8) -> torch.Tensor:\n",
    "    assert len(references) == len(candidates), \"Number of references and candidates must be equal\"\n",
    "    #references = [r + tokenizer.eos_token for r in references]\n",
    "    #candidates = [c + tokenizer.eos_token for c in candidates]\n",
    "    ref_tok = tokenizer(references, return_tensors='pt', padding=True)\n",
    "    cand_tok = tokenizer(candidates, return_tensors='pt', padding=True)\n",
    "    emb_ref = model(**ref_tok).logits[:, -1]\n",
    "    emb_cand = model(**cand_tok).logits[:, -1]\n",
    "    return torch.diag(util.cos_sim(emb_ref, emb_cand))\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\", \"This is a red cat with a hat.\", \"Today is a beautiful day.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(cos_score_batched([s1], [s2], model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CrossEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"finetuned-models/distilroberta-negation_old_wmt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are fat.\n",
      "You are not fat.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(s1)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(s2)\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mpredict([s1, s2]))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\", \"This is a red cat with a hat.\", \"Today is a beautiful day.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(model.predict([s1, s2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "6.0731967e-05"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\".\", \"this is a test sentence.\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "def demetr_accuracy_cross_encoder(dataset: pd.DataFrame, model:CrossEncoder) -> (float, np.array, np.array):\n",
    "    t_scores = []\n",
    "    hat_scores = []\n",
    "    empty_scores = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        #t_scores = torch.tensor(model.predict([dataset.eng_sent, dataset.mt_sent]))\n",
    "        t_scores.append(model.predict([row.eng_sent, row.mt_sent]))\n",
    "        #hat_scores = torch.tensor(model.predict([dataset.eng_sent, dataset.pert_sent]))\n",
    "        hat_scores.append(model.predict([row.eng_sent, row.pert_sent]))\n",
    "        print(t_scores[-1], hat_scores[-1])\n",
    "        empty_scores.append(model.predict([row.eng_sent, \".\"]))\n",
    "    t_scores = torch.tensor(t_scores)\n",
    "    hat_scores = torch.tensor(hat_scores)\n",
    "    empty_scores = torch.tensor(empty_scores)\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores, empty_scores\n",
    "\n",
    "\n",
    "def demetr_ratio_bleurt(dataset: pd.DataFrame, model:CrossEncoder) -> None:\n",
    "    acc, t_scores, hat_scores, empty_scores = demetr_accuracy_cross_encoder(dataset, model)\n",
    "    print(f\"Detection accuracy: {acc}\")\n",
    "    #empty_scores = torch.tensor(model.predict([dataset.eng_sent, [\".\"] * len(dataset)]))\n",
    "    ratio = (t_scores - hat_scores) / (t_scores - empty_scores)\n",
    "    ratio = sum(ratio) / len(dataset)\n",
    "    print(f\"Ratio: {ratio}\")\n",
    "\n",
    "\n",
    "def eval_models_on_dataset_cross_encoder(dataset: pd.DataFrame) -> None:\n",
    "    #print(\"** Base model\")\n",
    "    #demetr_ratio_bleurt(dataset, bleurt_scorer_orig)\n",
    "    print(\"** Fine-tuned model\")\n",
    "    demetr_ratio_bleurt(dataset, model)\n",
    "\n",
    "\n",
    "for pert_name, pert_data in perturbation_datasets.items():\n",
    "    print(\"* \", pert_name.capitalize())\n",
    "    eval_models_on_dataset_cross_encoder(pert_data)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Seq2seq score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "model_dir = Path(\"Guided Research WS22/finetuned-models/010/flan-t5-negate/checkpoint-2000\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It isn't rather hot in here.\", \"It's rather hot in here.\", \"It's not rather hot in here.\", \"It's rather cold in here.\", \"This isn't a red cat with a hat.\", 'This is not a red cat with a hat.', 'This is a black cat with a hat.', 'This is a white cat with a hat.']\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"negate: \"+ sent for sent in sents1]\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True)\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=512,\n",
    "    generation_config=GenerationConfig(\n",
    "        do_sample=False,\n",
    "        num_beams=4,\n",
    "        # penalty_alpha=0.5,\n",
    "        # top_k=10\n",
    "    ),\n",
    "    num_return_sequences=4\n",
    ")\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "# encode the inputs\n",
    "task_prefix = \"negate: \"\n",
    "\n",
    "encoding = tokenizer(\n",
    "    [task_prefix + sequence for sequence in sents1],\n",
    "    padding=\"longest\",\n",
    "    max_length=max_source_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# encode the targets\n",
    "target_encoding = tokenizer(sents2,\n",
    "    padding=\"longest\",\n",
    "    max_length=max_target_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "labels = target_encoding.input_ids\n",
    "\n",
    "# replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "# forward pass\n",
    "loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
    "loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "0.16529177129268646"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BLEURT score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"bleurtMaster\")\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... sp_model:None\n",
      "INFO:tensorflow:... dynamic_seq_length:False\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "from bleurtMaster.bleurt.score import BleurtScorer\n",
    "\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_checkpoint/export/bleurt_best/1680768470')\n",
    "#bleurt_scorer_ft_200 = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_new/export/bleurt_best/1683261322')\n",
    "#bleurt_scorer_ft_500 = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_new_500/export/bleurt_best/1683263275')\n",
    "#bleurt_scorer_ft_1000 = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_new_1000/export/bleurt_best/1683266066')\n",
    "#with tf.device(\"/GPU:0\")\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_-1_bleurt_checkpoint/export/bleurt_best/1680782762')\n",
    "bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649')\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_all_years/export/bleurt_best/1682672013')\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_22/export/bleurt_best/1682678300')\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_21/export/bleurt_best/1682684660')\n",
    "#bleurt_scorer_orig = BleurtScorer(checkpoint='bleurtMaster/bleurt/BLEURT-20')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's rather hot in here.\n",
      "It's rather cold in here.\n",
      "[0.2740648686885834]\n",
      "This is a red cat with a hat.\n",
      "This isn't a red cat with a hat.\n",
      "[0.4996153712272644]\n",
      "This is a red cat with a hat.\n",
      "This is not a red cat with a hat.\n",
      "[0.45220470428466797]\n",
      "Today is a beautiful day.\n",
      "Today is a wonderful day.\n",
      "[0.835724413394928]\n",
      "Today is a beautiful day.\n",
      ".\n",
      "[0.37826400995254517]\n",
      "I have time.\n",
      "I do not have time.\n",
      "[0.4257075786590576]\n",
      "I have time.\n",
      "I have no time.\n",
      "[0.4544045925140381]\n"
     ]
    }
   ],
   "source": [
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\",\n",
    "          \"This is a red cat with a hat.\", \"Today is a beautiful day.\", \"Today is a beautiful day.\",\n",
    "          \"I have time.\", \"I have time.\"]\n",
    "#sents1 = [\"You are fat.\", \"You are fat.\", \"You are fat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\", \".\",\n",
    "          \"I do not have time.\", \"I have no time.\"]\n",
    "#sents2 = [\"You are not fat.\", \"You are thin.\", \"You are not quite thin.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(bleurt_scorer_ft.score(references=[s1], candidates=[s2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Base_id33_empty\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9980000257492065\n",
      "Ratio: 1.0\n",
      "\n",
      "\n",
      "*  Base_id33_shuffle_trans\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 1.4298909902572632\n",
      "\n",
      "\n",
      "*  Base_id35_reference\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.004000000189989805\n",
      "Ratio: -0.7768175005912781\n",
      "\n",
      "\n",
      "*  Critical_id10_numbers_replaced\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.3529999852180481\n",
      "Ratio: 0.05665809288620949\n",
      "\n",
      "\n",
      "*  Critical_id11_gender\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.11100000143051147\n",
      "Ratio: 0.025292053818702698\n",
      "\n",
      "\n",
      "*  Critical_id20_shuffled\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7889999747276306\n",
      "Ratio: 0.049795474857091904\n",
      "\n",
      "\n",
      "*  Critical_id21_adj_adv_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7519999742507935\n",
      "Ratio: 0.08150798827409744\n",
      "\n",
      "\n",
      "*  Critical_id22_verb_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8149999976158142\n",
      "Ratio: 0.10993441194295883\n",
      "\n",
      "\n",
      "*  Critical_id23_noun_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8519999980926514\n",
      "Ratio: 0.11906155943870544\n",
      "\n",
      "\n",
      "*  Critical_id24_subj_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8019999861717224\n",
      "Ratio: 0.16398756206035614\n",
      "\n",
      "\n",
      "*  Critical_id25_ne_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.6389999985694885\n",
      "Ratio: 0.17438113689422607\n",
      "\n",
      "\n",
      "*  Critical_id4_codemix\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9819999933242798\n",
      "Ratio: 0.48938682675361633\n",
      "\n",
      "\n",
      "*  Critical_id6_addition\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8560000061988831\n",
      "Ratio: 0.09498316794633865\n",
      "\n",
      "\n",
      "*  Critical_id7_antonym\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.925000011920929\n",
      "Ratio: 0.23884330689907074\n",
      "\n",
      "\n",
      "*  Critical_id8_negation\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9779999852180481\n",
      "Ratio: 0.5098587870597839\n",
      "\n",
      "\n",
      "*  Critical_id9_ne_replaced\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.6779999732971191\n",
      "Ratio: 0.339224249124527\n",
      "\n",
      "\n",
      "*  Major_id17_tense\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.6579999923706055\n",
      "Ratio: 0.029855653643608093\n",
      "\n",
      "\n",
      "*  Major_id18_aspect\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.609000027179718\n",
      "Ratio: 0.01764807663857937\n",
      "\n",
      "\n",
      "*  Major_id19_question\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.953000009059906\n",
      "Ratio: 0.18426410853862762\n",
      "\n",
      "\n",
      "*  Major_id3_hypernym\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7850000262260437\n",
      "Ratio: 0.1140189915895462\n",
      "\n",
      "\n",
      "*  Major_id5_pp_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7369999885559082\n",
      "Ratio: 0.12639029324054718\n",
      "\n",
      "\n",
      "*  Minor_id12_conj_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.367000013589859\n",
      "Ratio: 0.018440643325448036\n",
      "\n",
      "\n",
      "*  Minor_id13_pos_shift\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8330000042915344\n",
      "Ratio: 0.07445309311151505\n",
      "\n",
      "\n",
      "*  Minor_id14_word_swap\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.4869999885559082\n",
      "Ratio: 8.102779975160956e-05\n",
      "\n",
      "\n",
      "*  Minor_id15_case\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.27300000190734863\n",
      "Ratio: 0.020632056519389153\n",
      "\n",
      "\n",
      "*  Minor_id16_function_word\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.5839999914169312\n",
      "Ratio: 0.03418702259659767\n",
      "\n",
      "\n",
      "*  Minor_id1_repeat2\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.5080000162124634\n",
      "Ratio: 0.008398797363042831\n",
      "\n",
      "\n",
      "*  Minor_id26_misspelled\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.953000009059906\n",
      "Ratio: 0.25737395882606506\n",
      "\n",
      "\n",
      "*  Minor_id27_char_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9399999976158142\n",
      "Ratio: 0.22731034457683563\n",
      "\n",
      "\n",
      "*  Minor_id28_final_punc_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8510000109672546\n",
      "Ratio: 0.07336151599884033\n",
      "\n",
      "\n",
      "*  Minor_id29_punc_addition\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9210000038146973\n",
      "Ratio: 0.06684736907482147\n",
      "\n",
      "\n",
      "*  Minor_id2_repeat4\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.5590000152587891\n",
      "Ratio: 0.019994404166936874\n",
      "\n",
      "\n",
      "*  Minor_id30_tokenized\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.01899999938905239\n",
      "Ratio: 0.0013893985887989402\n",
      "\n",
      "\n",
      "*  Minor_id31_full_lower\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.0\n",
      "Ratio: 0.0\n",
      "\n",
      "\n",
      "*  Minor_id32_first_lower\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.0020000000949949026\n",
      "Ratio: 3.1473660783376545e-05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def demetr_accuracy_bleurt(dataset: pd.DataFrame, bleurt_scorer:BleurtScorer) -> (float, np.array, np.array):\n",
    "    t_scores = torch.tensor(bleurt_scorer.score(references=dataset.eng_sent, candidates=dataset.mt_sent))\n",
    "    hat_scores = torch.tensor(bleurt_scorer.score(references=dataset.eng_sent, candidates=dataset.pert_sent))\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores\n",
    "\n",
    "\n",
    "def demetr_ratio_bleurt(dataset: pd.DataFrame, bleurt_scorer:BleurtScorer) -> float:\n",
    "    acc, t_scores, hat_scores = demetr_accuracy_bleurt(dataset, bleurt_scorer)\n",
    "    print(f\"Detection accuracy: {acc}\")\n",
    "    empty_scores = torch.tensor(bleurt_scorer.score(references=dataset.eng_sent, candidates=[\".\"] * len(dataset)))\n",
    "    ratio = (t_scores - hat_scores) / (t_scores - empty_scores)\n",
    "    ratio = sum(ratio) / len(dataset)\n",
    "    print(f\"Ratio: {ratio}\")\n",
    "    return ratio.item()\n",
    "\n",
    "\n",
    "def eval_models_on_dataset_bleurt(dataset: pd.DataFrame) -> dict|float:\n",
    "    \"\"\"\n",
    "    dataset_scores = {}\n",
    "    print(\"** 200 steps\")\n",
    "    dataset_scores[\"model_200\"] = demetr_ratio_bleurt(dataset, bleurt_scorer_ft_200)\n",
    "    print(\"** 500 steps\")\n",
    "    dataset_scores[\"model_500\"] = demetr_ratio_bleurt(dataset, bleurt_scorer_ft_500)\n",
    "    print(\"** 1000 steps\")\n",
    "    dataset_scores[\"model_1000\"] = demetr_ratio_bleurt(dataset, bleurt_scorer_ft_1000)\n",
    "    return dataset_scores\n",
    "    \"\"\"\n",
    "    print(\"** Fine-tuned model\")\n",
    "    return demetr_ratio_bleurt(dataset, bleurt_scorer_ft)\n",
    "\n",
    "demetr_scores = {}\n",
    "for pert_name, pert_data in perturbation_datasets.items():\n",
    "    print(\"* \", pert_name.capitalize())\n",
    "    dem_rat = eval_models_on_dataset_bleurt(pert_data)\n",
    "    demetr_scores[pert_name] = dem_rat\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649 does not appear to have a file named config.json. Checkout 'https://huggingface.co/bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TFAutoModelForSequenceClassification, AutoTokenizer\n\u001B[0;32m      3\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTFAutoModelForSequenceClassification\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_bleurt_score\u001B[39m(reference:\u001B[38;5;28mstr\u001B[39m, candidate:\u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:434\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    432\u001B[0m hub_kwargs \u001B[38;5;241m=\u001B[39m {name: kwargs\u001B[38;5;241m.\u001B[39mpop(name) \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m hub_kwargs_names \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m kwargs}\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[1;32m--> 434\u001B[0m     config, kwargs \u001B[38;5;241m=\u001B[39m AutoConfig\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    435\u001B[0m         pretrained_model_name_or_path,\n\u001B[0;32m    436\u001B[0m         return_unused_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    437\u001B[0m         trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code,\n\u001B[0;32m    438\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs,\n\u001B[0;32m    439\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    440\u001B[0m     )\n\u001B[0;32m    441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(config, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config\u001B[38;5;241m.\u001B[39mauto_map:\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m trust_remote_code:\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:852\u001B[0m, in \u001B[0;36mAutoConfig.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    850\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_or_path\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m pretrained_model_name_or_path\n\u001B[0;32m    851\u001B[0m trust_remote_code \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrust_remote_code\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 852\u001B[0m config_dict, unused_kwargs \u001B[38;5;241m=\u001B[39m PretrainedConfig\u001B[38;5;241m.\u001B[39mget_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    853\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto_map\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m trust_remote_code:\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:565\u001B[0m, in \u001B[0;36mPretrainedConfig.get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    563\u001B[0m original_kwargs \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(kwargs)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[1;32m--> 565\u001B[0m config_dict, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_config_dict(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict:\n\u001B[0;32m    567\u001B[0m     original_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m config_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\configuration_utils.py:620\u001B[0m, in \u001B[0;36mPretrainedConfig._get_config_dict\u001B[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[0m\n\u001B[0;32m    616\u001B[0m configuration_file \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_configuration_file\u001B[39m\u001B[38;5;124m\"\u001B[39m, CONFIG_NAME)\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    619\u001B[0m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m     resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    625\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    626\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m     commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m:\n\u001B[0;32m    636\u001B[0m     \u001B[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001B[39;00m\n\u001B[0;32m    637\u001B[0m     \u001B[38;5;66;03m# the original exception.\u001B[39;00m\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\utils\\hub.py:380\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(resolved_file):\n\u001B[0;32m    379\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _raise_exceptions_for_missing_entries:\n\u001B[1;32m--> 380\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    381\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not appear to have a file named \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfull_filename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Checkout \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    382\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrevision\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for available files.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    383\u001B[0m         )\n\u001B[0;32m    384\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649 does not appear to have a file named config.json. Checkout 'https://huggingface.co/bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649/None' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = 'bleurtMaster/neg_bleurt_antonym/export/bleurt_best/1683701649'\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def predict_bleurt_score(reference:str, candidate:str) -> None:\n",
    "    print(\"Reference: \", reference)\n",
    "    print(\"Candidate: \", candidate)\n",
    "    ####################################################################\n",
    "    # TODO Tokenize the reference and candidate and feed the tokenizer\n",
    "    # output into the model. Print the score prediction.\n",
    "    ####################################################################\n",
    "    tokenizer_output = tokenizer([reference], [candidate], return_tensors='pt', padding=True, truncation=True)\n",
    "    print(model(**tokenizer_output).logits.item())\n",
    "    ####################################################################\n",
    "\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\",\n",
    "          \"This is a red cat with a hat.\", \"Today is a beautiful day.\", \"Today is a beautiful day.\",\n",
    "          \"I have time.\", \"I have time.\"]\n",
    "#sents1 = [\"You are fat.\", \"You are fat.\", \"You are fat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\", \".\",\n",
    "          \"I do not have time.\", \"I have no time.\"]\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    predict_bleurt_score(s1, s2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nThis version of TensorFlow Probability requires TensorFlow version >= 2.11; Detected an installation of version 2.10.0. Please upgrade TensorFlow to proceed.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1110\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1109\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1006\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:688\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:883\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:73\u001B[0m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mquestion_answering\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m QuestionAnsweringArgumentHandler, QuestionAnsweringPipeline\n\u001B[1;32m---> 73\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtable_question_answering\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TableQuestionAnsweringArgumentHandler, TableQuestionAnsweringPipeline\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext2text_generation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SummarizationPipeline, Text2TextGenerationPipeline, TranslationPipeline\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\pipelines\\table_question_answering.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfp\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_tf_auto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     30\u001B[0m     TF_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING,\n\u001B[0;32m     31\u001B[0m     TF_MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING,\n\u001B[0;32m     32\u001B[0m )\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\tensorflow_probability\\__init__.py:23\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# from tensorflow_probability.google import staging  # DisableOnExport\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# from tensorflow_probability.google import tfp_google  # DisableOnExport\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# pylint: disable=wildcard-import\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:138\u001B[0m\n\u001B[0;32m    137\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m pkg_name \u001B[38;5;129;01min\u001B[39;00m _maybe_nonlazy_load:\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;43mdir\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpkg_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Forces loading the package from its lazy loader.\u001B[39;00m\n\u001B[0;32m    141\u001B[0m all_util\u001B[38;5;241m.\u001B[39mremove_undocumented(\u001B[38;5;18m__name__\u001B[39m, _lazy_load \u001B[38;5;241m+\u001B[39m _maybe_nonlazy_load)\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\lazy_loader.py:57\u001B[0m, in \u001B[0;36mLazyLoader.__dir__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__dir__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 57\u001B[0m   module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mdir\u001B[39m(module)\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\tensorflow_probability\\python\\internal\\lazy_loader.py:37\u001B[0m, in \u001B[0;36mLazyLoader._load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_first_access):\n\u001B[1;32m---> 37\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_on_first_access\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_first_access \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\tensorflow_probability\\python\\__init__.py:59\u001B[0m, in \u001B[0;36m_validate_tf_environment\u001B[1;34m(package)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (distutils\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m.\u001B[39mLooseVersion(tf\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m<\u001B[39m\n\u001B[0;32m     58\u001B[0m     distutils\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m.\u001B[39mLooseVersion(required_tensorflow_version)):\n\u001B[1;32m---> 59\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m     60\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis version of TensorFlow Probability requires TensorFlow \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     61\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mversion >= \u001B[39m\u001B[38;5;132;01m{required}\u001B[39;00m\u001B[38;5;124m; Detected an installation of version \u001B[39m\u001B[38;5;132;01m{present}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     62\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPlease upgrade TensorFlow to proceed.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     63\u001B[0m           required\u001B[38;5;241m=\u001B[39mrequired_tensorflow_version,\n\u001B[0;32m     64\u001B[0m           present\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39m__version__))\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (package \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmcmc\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[0;32m     67\u001B[0m     tf\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mtensor_float_32_execution_enabled()):\n\u001B[0;32m     68\u001B[0m   \u001B[38;5;66;03m# Must import here, because symbols get pruned to __all__.\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: This version of TensorFlow Probability requires TensorFlow version >= 2.11; Detected an installation of version 2.10.0. Please upgrade TensorFlow to proceed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mevaluate\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load\n\u001B[0;32m      3\u001B[0m eval_bleurt \u001B[38;5;241m=\u001B[39m load(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbleurt\u001B[39m\u001B[38;5;124m\"\u001B[39m, module_tpe\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m, checkpoint\u001B[38;5;241m=\u001B[39mmodel_name)\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\evaluate\\__init__.py:29\u001B[0m\n\u001B[0;32m     25\u001B[0m SCRIPTS_VERSION \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmain\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m version\u001B[38;5;241m.\u001B[39mparse(__version__)\u001B[38;5;241m.\u001B[39mis_devrelease \u001B[38;5;28;01melse\u001B[39;00m __version__\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m version\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation_suite\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EvaluationSuite\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     31\u001B[0m     AutomaticSpeechRecognitionEvaluator,\n\u001B[0;32m     32\u001B[0m     Evaluator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     41\u001B[0m     evaluator,\n\u001B[0;32m     42\u001B[0m )\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m push_to_hub\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\evaluate\\evaluation_suite\\__init__.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset, DownloadMode, load_dataset\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Version\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m evaluator\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mloading\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m evaluation_module_factory\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DownloadConfig\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\evaluate\\evaluator\\__init__.py:27\u001B[0m\n\u001B[0;32m     23\u001B[0m     TRANSFORMERS_AVAILABLE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict, List\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautomatic_speech_recognition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutomaticSpeechRecognitionEvaluator\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Evaluator\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage_classification\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageClassificationEvaluator\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\evaluate\\evaluator\\automatic_speech_recognition.py:22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EvaluationModule\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m add_end_docstrings, add_start_docstrings\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EVALUATOR_COMPUTE_RETURN_DOCSTRING, EVALUTOR_COMPUTE_START_DOCSTRING, Evaluator\n\u001B[0;32m     25\u001B[0m TASK_DOCUMENTATION \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;124m    Examples:\u001B[39m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;124m    ```python\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;124m    ```\u001B[39m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mAutomaticSpeechRecognitionEvaluator\u001B[39;00m(Evaluator):\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\evaluate\\evaluator\\base.py:34\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pipeline, pipeline\n\u001B[0;32m     36\u001B[0m     TRANSFORMERS_AVAILABLE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1075\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[1;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1100\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1098\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m-> 1100\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1101\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32md:\\users\\miriam anschütz\\documents\\workspaces\\pycharm projects\\negation_aware_evaluation\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py:1112\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1112\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1113\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1114\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1115\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nThis version of TensorFlow Probability requires TensorFlow version >= 2.11; Detected an installation of version 2.10.0. Please upgrade TensorFlow to proceed."
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "eval_bleurt = load(\"bleurt\", module_tpe=\"metric\", checkpoint=model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eval on DEMETR data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_demetr_dataset(data_path:str) -> pd.DataFrame:\n",
    "    df:pd.DataFrame = pd.read_json(demetr_data_path + data_path)\n",
    "    return df\n",
    "\n",
    "demetr_data_path = \"demetr-main/dataset/\"\n",
    "perturbation_datasets = {\n",
    "    \"negation\": load_demetr_dataset(\"critical_id8_negation.json\"),\n",
    "    \"antonym\": load_demetr_dataset(\"critical_id7_antonym.json\"),\n",
    "    \"baseline_shuffle\": load_demetr_dataset(\"base_id33_shuffle_trans.json\"),\n",
    "    \"verb removed\": load_demetr_dataset(\"critical_id22_verb_removed.json\"),\n",
    "    \"hypernym\": load_demetr_dataset(\"major_id3_hypernym.json\"),\n",
    "    #\"gender\": load_demetr_dataset(\"critical_id11_gender.json\"),\n",
    "    #\"repeat4\": load_demetr_dataset(\"minor_id2_repeat4.json\")\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "perturbation_datasets = {}\n",
    "for filename in os.listdir(demetr_data_path):\n",
    "    perturbation_datasets[filename.replace(\".json\", \"\")] = load_demetr_dataset(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def demetr_accuracy_sent_transform(dataset: pd.DataFrame, model:SentenceTransformer, score_function) -> (float, np.array, np.array):\n",
    "    t_scores = score_function(dataset.eng_sent, dataset.mt_sent, model)\n",
    "    hat_scores = score_function(dataset.eng_sent, dataset.pert_sent, model)\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores\n",
    "\n",
    "batch_size = 16\n",
    "def batchwise_score(sents1, sents2, model, score_function):\n",
    "    scores = []\n",
    "    for i in range(0, len(sents1), batch_size):\n",
    "        scores.append(score_function(sents1[i:i+batch_size], sents2[i:i+batch_size], model))\n",
    "    return scores\n",
    "\n",
    "def demetr_accuracy(dataset: pd.DataFrame, model, score_function) -> (float, np.array, np.array):\n",
    "    t_scores = batchwise_score(dataset.eng_sent, dataset.mt_sent, model, score_function)\n",
    "    hat_scores = batchwise_score(dataset.eng_sent, dataset.pert_sent, model, score_function)\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores\n",
    "\n",
    "#def demetr_ratio(dataset: pd.DataFrame, model:SentenceTransformer, score_function) -> None:\n",
    "def demetr_ratio(dataset: pd.DataFrame, model, score_function) -> None:\n",
    "    acc, t_scores, hat_scores = demetr_accuracy_sent_transform(dataset, model, score_function)\n",
    "    print(f\"Detection accuracy: {acc}\")\n",
    "    empty_scores = score_function(dataset.eng_sent, [\".\"] * len(dataset), model)\n",
    "    ratio = (t_scores - hat_scores) / (t_scores - empty_scores)\n",
    "    ratio = sum(ratio) / len(dataset)\n",
    "    print(f\"Ratio: {ratio}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Base_id33_empty\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 1.0\n",
      "\n",
      "\n",
      "*  Base_id33_shuffle_trans\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 0.9917993545532227\n",
      "\n",
      "\n",
      "*  Base_id35_reference\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.0\n",
      "Ratio: -0.12595725059509277\n",
      "\n",
      "\n",
      "*  Critical_id10_numbers_replaced\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.35499998927116394\n",
      "Ratio: 0.01434969063848257\n",
      "\n",
      "\n",
      "*  Critical_id11_gender\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.1120000034570694\n",
      "Ratio: 0.005827408749610186\n",
      "\n",
      "\n",
      "*  Critical_id20_shuffled\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9879999756813049\n",
      "Ratio: 0.20115171372890472\n",
      "\n",
      "\n",
      "*  Critical_id21_adj_adv_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7839999794960022\n",
      "Ratio: 0.03920629620552063\n",
      "\n",
      "\n",
      "*  Critical_id22_verb_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8009999990463257\n",
      "Ratio: 0.03977161645889282\n",
      "\n",
      "\n",
      "*  Critical_id23_noun_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8529999852180481\n",
      "Ratio: 0.04186835139989853\n",
      "\n",
      "\n",
      "*  Critical_id24_subj_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8709999918937683\n",
      "Ratio: 0.04157876595854759\n",
      "\n",
      "\n",
      "*  Critical_id25_ne_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.6209999918937683\n",
      "Ratio: 0.023250360041856766\n",
      "\n",
      "\n",
      "*  Critical_id4_codemix\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9269999861717224\n",
      "Ratio: 0.05639884993433952\n",
      "\n",
      "\n",
      "*  Critical_id6_addition\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9300000071525574\n",
      "Ratio: 0.07171814143657684\n",
      "\n",
      "\n",
      "*  Critical_id7_antonym\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.953000009059906\n",
      "Ratio: 0.24911931157112122\n",
      "\n",
      "\n",
      "*  Critical_id8_negation\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9940000176429749\n",
      "Ratio: 0.621858537197113\n",
      "\n",
      "\n",
      "*  Critical_id9_ne_replaced\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.6669999957084656\n",
      "Ratio: 0.043876491487026215\n",
      "\n",
      "\n",
      "*  Major_id17_tense\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8870000243186951\n",
      "Ratio: 0.03417440876364708\n",
      "\n",
      "\n",
      "*  Major_id18_aspect\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8059999942779541\n",
      "Ratio: 0.012704300694167614\n",
      "\n",
      "\n",
      "*  Major_id19_question\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.9020000100135803\n",
      "Ratio: 0.07197760790586472\n",
      "\n",
      "\n",
      "*  Major_id3_hypernym\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.796999990940094\n",
      "Ratio: 0.04432525113224983\n",
      "\n",
      "\n",
      "*  Major_id5_pp_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7889999747276306\n",
      "Ratio: 0.05292458459734917\n",
      "\n",
      "\n",
      "*  Minor_id12_conj_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.5709999799728394\n",
      "Ratio: 0.007587785832583904\n",
      "\n",
      "\n",
      "*  Minor_id13_pos_shift\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8209999799728394\n",
      "Ratio: 0.02034856379032135\n",
      "\n",
      "\n",
      "*  Minor_id14_word_swap\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7879999876022339\n",
      "Ratio: 0.011066698469221592\n",
      "\n",
      "\n",
      "*  Minor_id15_case\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.2840000092983246\n",
      "Ratio: 0.003949040547013283\n",
      "\n",
      "\n",
      "*  Minor_id16_function_word\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7400000095367432\n",
      "Ratio: 0.035872265696525574\n",
      "\n",
      "\n",
      "*  Minor_id1_repeat2\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.746999979019165\n",
      "Ratio: 0.004419686272740364\n",
      "\n",
      "\n",
      "*  Minor_id26_misspelled\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8579999804496765\n",
      "Ratio: 0.03235688805580139\n",
      "\n",
      "\n",
      "*  Minor_id27_char_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.875\n",
      "Ratio: 0.04145697504281998\n",
      "\n",
      "\n",
      "*  Minor_id28_final_punc_removed\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8100000023841858\n",
      "Ratio: 0.011892374604940414\n",
      "\n",
      "\n",
      "*  Minor_id29_punc_addition\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.7839999794960022\n",
      "Ratio: 0.009153865277767181\n",
      "\n",
      "\n",
      "*  Minor_id2_repeat4\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.8700000047683716\n",
      "Ratio: 0.01400985848158598\n",
      "\n",
      "\n",
      "*  Minor_id30_tokenized\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.023000000044703484\n",
      "Ratio: 0.0005539465928450227\n",
      "\n",
      "\n",
      "*  Minor_id31_full_lower\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.0\n",
      "Ratio: 0.0\n",
      "\n",
      "\n",
      "*  Minor_id32_first_lower\n",
      "** Fine-tuned model\n",
      "Detection accuracy: 0.0020000000949949026\n",
      "Ratio: 5.641231382469414e-06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_models_on_dataset(dataset:pd.DataFrame, score_function) -> None:\n",
    "    #print(\"** Base model\")\n",
    "    #demetr_ratio(dataset, base_model, score_function)\n",
    "    #demetr_ratio(dataset, model, score_function)\n",
    "    print(\"** Fine-tuned model\")\n",
    "    demetr_ratio(dataset, finetuned_model_wmt, score_function)\n",
    "\n",
    "for pert_name, pert_data in perturbation_datasets.items():\n",
    "    print(\"* \", pert_name.capitalize())\n",
    "    eval_models_on_dataset(pert_data, cos_score_batched)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Semsimilarity choose right antonym"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       idx  label                      input  \\\n0        0      2            You're not fat.   \n1        1      2            You're not fat.   \n2        2      2          It's not healthy.   \n3        3      2     That's not acceptable.   \n4        4      2            I'm not guilty.   \n...    ...    ...                        ...   \n3147  3147      2     I know it is possible.   \n3148  3148      2     I know it is possible.   \n3149  3149      2  No, it's a good idea, no.   \n3150  3150      2  No, it's a good idea, no.   \n3151  3151      2               He's asleep.   \n\n                                              sentences  \n0         [You're not thin., You're fat., You're thin.]  \n1     [You're not nonfat., You're fat., You're nonfat.]  \n2     [It's not unhealthy., It's healthy., It's unhe...  \n3     [That's not unacceptable., That's acceptable.,...  \n4       [I'm not innocent., I'm guilty., I'm innocent.]  \n...                                                 ...  \n3147  [I know it is impossible., I know it is not po...  \n3148  [I know it is actual., I know it is not possib...  \n3149  [No, it's a bad idea, no., No, it's not a good...  \n3150  [No, it's an evil idea, no., No, it's not a go...  \n3151   [He's awake., He's not asleep., He's not awake.]  \n\n[3152 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>label</th>\n      <th>input</th>\n      <th>sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>You're not fat.</td>\n      <td>[You're not thin., You're fat., You're thin.]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>You're not fat.</td>\n      <td>[You're not nonfat., You're fat., You're nonfat.]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>It's not healthy.</td>\n      <td>[It's not unhealthy., It's healthy., It's unhe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2</td>\n      <td>That's not acceptable.</td>\n      <td>[That's not unacceptable., That's acceptable.,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2</td>\n      <td>I'm not guilty.</td>\n      <td>[I'm not innocent., I'm guilty., I'm innocent.]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3147</th>\n      <td>3147</td>\n      <td>2</td>\n      <td>I know it is possible.</td>\n      <td>[I know it is impossible., I know it is not po...</td>\n    </tr>\n    <tr>\n      <th>3148</th>\n      <td>3148</td>\n      <td>2</td>\n      <td>I know it is possible.</td>\n      <td>[I know it is actual., I know it is not possib...</td>\n    </tr>\n    <tr>\n      <th>3149</th>\n      <td>3149</td>\n      <td>2</td>\n      <td>No, it's a good idea, no.</td>\n      <td>[No, it's a bad idea, no., No, it's not a good...</td>\n    </tr>\n    <tr>\n      <th>3150</th>\n      <td>3150</td>\n      <td>2</td>\n      <td>No, it's a good idea, no.</td>\n      <td>[No, it's an evil idea, no., No, it's not a go...</td>\n    </tr>\n    <tr>\n      <th>3151</th>\n      <td>3151</td>\n      <td>2</td>\n      <td>He's asleep.</td>\n      <td>[He's awake., He's not asleep., He's not awake.]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3152 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open(\"SemAntoNeg_v1.0.json\") as file_obj:\n",
    "    data_list = []\n",
    "    for line in file_obj:\n",
    "        data_list.append(json.loads(line))\n",
    "semsim = pd.DataFrame(data_list)\n",
    "semsim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3152/3152 [05:05<00:00, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "num_samples = 3\n",
    "base_prefs = []\n",
    "ft_prefs = []#{200: [], 500: [], 1000: []}\n",
    "for inp, sents in tqdm(zip(semsim.input.values, semsim.sentences.values), total=len(semsim)):\n",
    "  base_scores = cos_score_batched([inp] * 3, sents, base_model)\n",
    "  base_prefs.append(torch.argmax(base_scores).item())\n",
    "  ft_scores = cos_score_batched([inp] * 3, sents, finetuned_model)\n",
    "  ft_prefs.append(torch.argmax(ft_scores).item())\n",
    "  #base_scores = torch.tensor(bleurt_scorer_orig.score(references=[inp] * 3, candidates=sents))\n",
    "  #ft_scores = torch.tensor(bleurt_scorer_ft_200.score(references=[inp] * 3, candidates=sents))\n",
    "  #ft_prefs[200].append(torch.argmax(ft_scores).item())\n",
    "  #ft_scores = torch.tensor(bleurt_scorer_ft_500.score(references=[inp] * 3, candidates=sents))\n",
    "  #ft_prefs[500].append(torch.argmax(ft_scores).item())\n",
    "  #ft_scores = torch.tensor(bleurt_scorer_ft_1000.score(references=[inp] * 3, candidates=sents))\n",
    "  #ft_prefs[1000].append(torch.argmax(ft_scores).item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned 200 model accuracy:  0.012373096446700508\n",
      "Fine-tuned 500 model accuracy:  0.01649746192893401\n",
      "Fine-tuned 1000 model accuracy:  0.015545685279187817\n"
     ]
    }
   ],
   "source": [
    "# BLEURT eval\n",
    "from sklearn.metrics import accuracy_score\n",
    "labels = semsim.label.values[:len(ft_prefs[200])]\n",
    "#print(\"Base model accuracy: \", accuracy_score(labels, base_prefs))\n",
    "print(\"Fine-tuned 200 model accuracy: \", accuracy_score(labels, ft_prefs[200]))\n",
    "print(\"Fine-tuned 500 model accuracy: \", accuracy_score(labels, ft_prefs[500]))\n",
    "print(\"Fine-tuned 1000 model accuracy: \", accuracy_score(labels, ft_prefs[1000]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.31916243654822335\n",
      "Fine-tuned model accuracy:  0.6211928934010152\n"
     ]
    }
   ],
   "source": [
    "# SBERT scores\n",
    "from sklearn.metrics import accuracy_score\n",
    "labels = semsim.label.values[:len(ft_prefs)]\n",
    "print(\"Base model accuracy: \", accuracy_score(labels, base_prefs))\n",
    "print(\"Fine-tuned model accuracy: \", accuracy_score(labels, ft_prefs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EvalEval perturbations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Perturbations  annotator 1  annotator 2  \\\n0                        Remove punctuation            0            2   \n1                    Spelling mistake/typos            2            2   \n2                  Missing (nltk) stopwords            4            5   \n3                 Subject-verb disagreement            4            2   \n4                            Jumbling words           10            9   \n5                          Adding Negations            9           10   \n6                      Change number values            6           10   \n7                              Change names            7           10   \n8                   Removing named entities            4            7   \n9                    Retain only stop words            9           10   \n10  Removing adjectives that precede a noun            2            2   \n11                               Drop words            5            8   \n12                  Replacing with antonyms           10           10   \n13                                 Hyponyms            5           10   \n14                           repeat Phrases            6            3   \n15                           add extra text            4            8   \n16                             contractions            0            0   \n17                               Expansions            0            0   \n18                                num2words            0            0   \n19                  Replacing with synonyms            0            0   \n20                      Alternate reference            0            0   \n\n    annotator 3  annotator 4  annotator 5  annotator 6  annotator 7  \\\n0             1            1          1.0            1            0   \n1             4            3          2.0            4            1   \n2             2            3          3.0            1            4   \n3             1            2          2.0            1            1   \n4             5           10          7.0            8           10   \n5            10           10          9.5           10           10   \n6             9            8          8.0           10            9   \n7             7            8          9.0            6            5   \n8             2            5          7.0            2            3   \n9            10           10          9.5           10           10   \n10            1            1          3.0            2            2   \n11            4            5          7.0            5            4   \n12            9           10          9.5           10           10   \n13            5            8          8.0            5            5   \n14            2            5          4.0            6            4   \n15            4            8          5.0            7            4   \n16            0            0          0.0            0            0   \n17            0            0          0.0            0            0   \n18            0            0          0.0            0            0   \n19            1            0          0.0            0            0   \n20            0            0          0.0            0            0   \n\n    annotator 8  annotator 9  annotator 10  annotator 11  annotator 12  \\\n0             2            3             1             0             2   \n1             4            2             2             4             3   \n2             5            5             2             5             4   \n3             4            1             1             3             1   \n4             6            6             5            10             8   \n5             7           10            10            10             8   \n6             4           10             9            10             6   \n7             7           10             8            10             5   \n8             6            7             3            10             5   \n9            10           10            10            10             9   \n10            3            4             3             8             0   \n11            6            7             5            10             5   \n12            7           10            10            10             6   \n13            4           10             5            10             1   \n14            7            0             7             3             5   \n15            7            7             7             8             4   \n16            0            0             0             0             0   \n17            0            0             0             0             0   \n18            0            0             0             0             0   \n19            0            3             1             0             0   \n20            0            0             0             0             0   \n\n    annotator 13  annotator 14  annotator 15  \n0              1             0             0  \n1              1             2             1  \n2              3             3             0  \n3              4             3             0  \n4              9             9             4  \n5             10             8            10  \n6             10             8             9  \n7             10             8             6  \n8              8             8             0  \n9             10             9            10  \n10             2             0             1  \n11             8             8             5  \n12            10             8            10  \n13            10             8             2  \n14             5             3             2  \n15             8             5             5  \n16             0             0             0  \n17             0             0             0  \n18             0             0             0  \n19             0             0             0  \n20             0             0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Perturbations</th>\n      <th>annotator 1</th>\n      <th>annotator 2</th>\n      <th>annotator 3</th>\n      <th>annotator 4</th>\n      <th>annotator 5</th>\n      <th>annotator 6</th>\n      <th>annotator 7</th>\n      <th>annotator 8</th>\n      <th>annotator 9</th>\n      <th>annotator 10</th>\n      <th>annotator 11</th>\n      <th>annotator 12</th>\n      <th>annotator 13</th>\n      <th>annotator 14</th>\n      <th>annotator 15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Remove punctuation</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spelling mistake/typos</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Missing (nltk) stopwords</td>\n      <td>4</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Subject-verb disagreement</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jumbling words</td>\n      <td>10</td>\n      <td>9</td>\n      <td>5</td>\n      <td>10</td>\n      <td>7.0</td>\n      <td>8</td>\n      <td>10</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>10</td>\n      <td>8</td>\n      <td>9</td>\n      <td>9</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Adding Negations</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9.5</td>\n      <td>10</td>\n      <td>10</td>\n      <td>7</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Change number values</td>\n      <td>6</td>\n      <td>10</td>\n      <td>9</td>\n      <td>8</td>\n      <td>8.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Change names</td>\n      <td>7</td>\n      <td>10</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n      <td>5</td>\n      <td>10</td>\n      <td>8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Removing named entities</td>\n      <td>4</td>\n      <td>7</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>3</td>\n      <td>10</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Retain only stop words</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9.5</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Removing adjectives that precede a noun</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Drop words</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7.0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>5</td>\n      <td>10</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Replacing with antonyms</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n      <td>9.5</td>\n      <td>10</td>\n      <td>10</td>\n      <td>7</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Hyponyms</td>\n      <td>5</td>\n      <td>10</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>10</td>\n      <td>5</td>\n      <td>10</td>\n      <td>1</td>\n      <td>10</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>repeat Phrases</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>add extra text</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4</td>\n      <td>8</td>\n      <td>5.0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>8</td>\n      <td>4</td>\n      <td>8</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>contractions</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Expansions</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>num2words</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Replacing with synonyms</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Alternate reference</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "human_score_mt = pd.read_csv(\"EvalEvalMain/data/MachineTranslation.csv\")\n",
    "human_score_mt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}