{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from sentence_transformers import models, losses, datasets\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence Transformer score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "timestamp = \"2023-02-17_15-02-13\"\n",
    "project_base_path = Path(\"Guided Research WS22\")\n",
    "negation_dataset = project_base_path / \"data/negation_dataset_labeled.tsv\"\n",
    "\n",
    "\n",
    "base_model = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "output_model_name = f\"{base_model.split('/')[1]}-negation\"  # TODO.\n",
    "model_save_path = str(project_base_path / f\"finetuned-models/{timestamp}/{output_model_name}\")\n",
    "model_save_path_wmt = \"finetuned-models/all-mpnet-base-v2-negation_wmt\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": "SentenceTransformer(\n  (0): Transformer({'max_seq_length': 75, 'do_lower_case': False}) with Transformer model: MPNetModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = SentenceTransformer(model_save_path)\n",
    "finetuned_model_wmt = SentenceTransformer(model_save_path_wmt)\n",
    "base_model = SentenceTransformer(base_model)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "base_model.to(device)\n",
    "finetuned_model.to(device)\n",
    "finetuned_model_wmt.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's rather hot in here.\n",
      "It's rather cold in here.\n",
      "Base tensor([0.6409])\n",
      "FT tensor([0.3928])\n",
      "FT WMT tensor([0.8731])\n",
      "This is a red cat with a hat.\n",
      "This isn't a red cat with a hat.\n",
      "Base tensor([0.8470])\n",
      "FT tensor([0.5079])\n",
      "FT WMT tensor([0.8432])\n",
      "This is a red cat with a hat.\n",
      "This is not a red cat with a hat.\n",
      "Base tensor([0.8495])\n",
      "FT tensor([0.4682])\n",
      "FT WMT tensor([0.8455])\n",
      "Today is a beautiful day.\n",
      "Today is a wonderful day.\n",
      "Base tensor([0.8489])\n",
      "FT tensor([0.8935])\n",
      "FT WMT tensor([0.9507])\n"
     ]
    }
   ],
   "source": [
    "def cos_score(reference: str, candidate: str, model:SentenceTransformer) -> float:\n",
    "    emb_ref = model.encode(reference)\n",
    "    emb_cand = model.encode(candidate)\n",
    "    return util.cos_sim(emb_ref, emb_cand).item()\n",
    "\n",
    "def cos_score_batched(references: list, candidates: list, model: SentenceTransformer, batch_size=8) -> torch.Tensor:\n",
    "    assert len(references) == len(candidates), \"Number of references and candidates must be equal\"\n",
    "    emb_ref = model.encode(references, batch_size=batch_size)\n",
    "    emb_cand = model.encode(candidates, batch_size=batch_size)\n",
    "    return torch.diag(util.cos_sim(emb_ref, emb_cand))\n",
    "\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\"]\n",
    "#print(\"Base model score\", cos_score(sents1[0], sents2[0], base_model))\n",
    "#print(\"Fine-tuned model score\", cos_score(sents1[0], sents2[0], finetuned_model))\n",
    "#print(\"\\n\")\n",
    "#print(\"Base model score\", cos_score_batched(sents1, sents2, base_model))\n",
    "#print(\"Fine-tuned model score\", cos_score_batched(sents1, sents2, finetuned_model))\n",
    "#print(\"WMT Fine-tuned model score\", cos_score_batched(sents1, sents2, finetuned_model_wmt))\n",
    "\n",
    "\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\", \"This is a red cat with a hat.\", \"Today is a beautiful day.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(\"Base\", cos_score_batched([s1], [s2], base_model))\n",
    "    print(\"FT\", cos_score_batched([s1], [s2], finetuned_model))\n",
    "    print(\"FT WMT\", cos_score_batched([s1], [s2], finetuned_model_wmt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NegBERT score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"joey234/cuenb\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"BERTNOT/output\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"joey234/cuenb\")\n",
    "#model = AutoModelForMaskedLM.from_pretrained(\"BERTNOT/output_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 11, 50265])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok = tokenizer(\"This is a red cat with a hat.\", return_tensors='pt')\n",
    "model(**tok).logits.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['<s>This is a red cat with a hat.</s>']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(tok['input_ids'], skip_special_tokens=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's rather hot in here.\n",
      "It's rather cold in here.\n",
      "tensor([0.9931], grad_fn=<DiagBackward0>)\n",
      "This is a red cat with a hat.\n",
      "This isn't a red cat with a hat.\n",
      "tensor([0.8886], grad_fn=<DiagBackward0>)\n",
      "This is a red cat with a hat.\n",
      "This is not a red cat with a hat.\n",
      "tensor([0.7516], grad_fn=<DiagBackward0>)\n",
      "Today is a beautiful day.\n",
      "Today is a wonderful day.\n",
      "tensor([0.9886], grad_fn=<DiagBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def cos_score_batched(references: list, candidates: list, model: AutoModelForMaskedLM, batch_size=8) -> torch.Tensor:\n",
    "    assert len(references) == len(candidates), \"Number of references and candidates must be equal\"\n",
    "    #references = [r + tokenizer.eos_token for r in references]\n",
    "    #candidates = [c + tokenizer.eos_token for c in candidates]\n",
    "    ref_tok = tokenizer(references, return_tensors='pt', padding=True)\n",
    "    cand_tok = tokenizer(candidates, return_tensors='pt', padding=True)\n",
    "    emb_ref = model(**ref_tok).logits[:, -1]\n",
    "    emb_cand = model(**cand_tok).logits[:, -1]\n",
    "    return torch.diag(util.cos_sim(emb_ref, emb_cand))\n",
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\", \"This is a red cat with a hat.\", \"Today is a beautiful day.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(cos_score_batched([s1], [s2], model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CrossEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"finetuned-models/distilroberta-negation_old_wmt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are fat.\n",
      "You are not fat.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(s1)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(s2)\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mpredict([s1, s2]))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\", \"This is a red cat with a hat.\", \"Today is a beautiful day.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(model.predict([s1, s2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "6.0731967e-05"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\".\", \"this is a test sentence.\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "def demetr_accuracy_cross_encoder(dataset: pd.DataFrame, model:CrossEncoder) -> (float, np.array, np.array):\n",
    "    t_scores = []\n",
    "    hat_scores = []\n",
    "    empty_scores = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        #t_scores = torch.tensor(model.predict([dataset.eng_sent, dataset.mt_sent]))\n",
    "        t_scores.append(model.predict([row.eng_sent, row.mt_sent]))\n",
    "        #hat_scores = torch.tensor(model.predict([dataset.eng_sent, dataset.pert_sent]))\n",
    "        hat_scores.append(model.predict([row.eng_sent, row.pert_sent]))\n",
    "        print(t_scores[-1], hat_scores[-1])\n",
    "        empty_scores.append(model.predict([row.eng_sent, \".\"]))\n",
    "    t_scores = torch.tensor(t_scores)\n",
    "    hat_scores = torch.tensor(hat_scores)\n",
    "    empty_scores = torch.tensor(empty_scores)\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores, empty_scores\n",
    "\n",
    "\n",
    "def demetr_ratio_bleurt(dataset: pd.DataFrame, model:CrossEncoder) -> None:\n",
    "    acc, t_scores, hat_scores, empty_scores = demetr_accuracy_cross_encoder(dataset, model)\n",
    "    print(f\"Detection accuracy: {acc}\")\n",
    "    #empty_scores = torch.tensor(model.predict([dataset.eng_sent, [\".\"] * len(dataset)]))\n",
    "    ratio = (t_scores - hat_scores) / (t_scores - empty_scores)\n",
    "    ratio = sum(ratio) / len(dataset)\n",
    "    print(f\"Ratio: {ratio}\")\n",
    "\n",
    "\n",
    "def eval_models_on_dataset_cross_encoder(dataset: pd.DataFrame) -> None:\n",
    "    #print(\"** Base model\")\n",
    "    #demetr_ratio_bleurt(dataset, bleurt_scorer_orig)\n",
    "    print(\"** Fine-tuned model\")\n",
    "    demetr_ratio_bleurt(dataset, model)\n",
    "\n",
    "\n",
    "for pert_name, pert_data in perturbation_datasets.items():\n",
    "    print(\"* \", pert_name.capitalize())\n",
    "    eval_models_on_dataset_cross_encoder(pert_data)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Seq2seq score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, GenerationConfig"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "model_dir = Path(\"Guided Research WS22/finetuned-models/010/flan-t5-negate/checkpoint-2000\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It isn't rather hot in here.\", \"It's rather hot in here.\", \"It's not rather hot in here.\", \"It's rather cold in here.\", \"This isn't a red cat with a hat.\", 'This is not a red cat with a hat.', 'This is a black cat with a hat.', 'This is a white cat with a hat.']\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"negate: \"+ sent for sent in sents1]\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True)\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=512,\n",
    "    generation_config=GenerationConfig(\n",
    "        do_sample=False,\n",
    "        num_beams=4,\n",
    "        # penalty_alpha=0.5,\n",
    "        # top_k=10\n",
    "    ),\n",
    "    num_return_sequences=4\n",
    ")\n",
    "decoded_output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "# encode the inputs\n",
    "task_prefix = \"negate: \"\n",
    "\n",
    "encoding = tokenizer(\n",
    "    [task_prefix + sequence for sequence in sents1],\n",
    "    padding=\"longest\",\n",
    "    max_length=max_source_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# encode the targets\n",
    "target_encoding = tokenizer(sents2,\n",
    "    padding=\"longest\",\n",
    "    max_length=max_target_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "labels = target_encoding.input_ids\n",
    "\n",
    "# replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "# forward pass\n",
    "loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
    "loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "0.16529177129268646"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BLEURT score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"bleurtMaster\")\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 13331510361615484227\n xla_global_id: -1]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint bleurtMaster/neg_bleurt_new/export/bleurt_best/1683261322.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... sp_model:None\n",
      "INFO:tensorflow:... dynamic_seq_length:False\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "INFO:tensorflow:Reading checkpoint bleurtMaster/neg_bleurt_new_500/export/bleurt_best/1683263275.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... sp_model:None\n",
      "INFO:tensorflow:... dynamic_seq_length:False\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n",
      "INFO:tensorflow:Reading checkpoint bleurtMaster/neg_bleurt_new_1000/export/bleurt_best/1683266066.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint bert_custom\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:bert_custom\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:vocab.txt\n",
      "INFO:tensorflow:... do_lower_case:True\n",
      "INFO:tensorflow:... sp_model:None\n",
      "INFO:tensorflow:... dynamic_seq_length:False\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating WordPiece tokenizer.\n",
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n",
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "from bleurtMaster.bleurt.score import BleurtScorer\n",
    "\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_checkpoint/export/bleurt_best/1680768470')\n",
    "bleurt_scorer_ft_200 = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_new/export/bleurt_best/1683261322')\n",
    "bleurt_scorer_ft_500 = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_new_500/export/bleurt_best/1683263275')\n",
    "bleurt_scorer_ft_1000 = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_new_1000/export/bleurt_best/1683266066')\n",
    "#with tf.device(\"/GPU:0\")\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_-1_bleurt_checkpoint/export/bleurt_best/1680782762')\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_all_years/export/bleurt_best/1682672013')\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_22/export/bleurt_best/1682678300')\n",
    "#bleurt_scorer_ft = BleurtScorer(checkpoint='bleurtMaster/neg_bleurt_21/export/bleurt_best/1682684660')\n",
    "#bleurt_scorer_orig = BleurtScorer(checkpoint='bleurtMaster/bleurt/BLEURT-20')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are fat.\n",
      "You are not fat.\n",
      "[0.156449556350708]\n",
      "You are fat.\n",
      "You are thin.\n",
      "[-0.6134893298149109]\n",
      "You are fat.\n",
      "You are not quite thin.\n",
      "[-0.6198661923408508]\n"
     ]
    }
   ],
   "source": [
    "sents1 = [\"It's rather hot in here.\", \"This is a red cat with a hat.\",\n",
    "          \"This is a red cat with a hat.\", \"Today is a beautiful day.\", \"Today is a beautiful day.\"]\n",
    "sents1 = [\"You are fat.\", \"You are fat.\", \"You are fat.\"]\n",
    "sents2 = [\"It's rather cold in here.\", \"This isn't a red cat with a hat.\", \"This is not a red cat with a hat.\", \"Today is a wonderful day.\", \".\"]\n",
    "sents2 = [\"You are not fat.\", \"You are thin.\", \"You are not quite thin.\"]\n",
    "\n",
    "for s1, s2 in zip(sents1, sents2):\n",
    "    print(s1)\n",
    "    print(s2)\n",
    "    print(bleurt_scorer_ft.score(references=[s1], candidates=[s2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Base_id33_empty\n",
      "** 200 steps\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 1.0\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9990000128746033\n",
      "Ratio: 1.0\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9959999918937683\n",
      "Ratio: 1.0\n",
      "\n",
      "\n",
      "*  Base_id33_shuffle_trans\n",
      "** 200 steps\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 1.2333643436431885\n",
      "** 500 steps\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 1.4536385536193848\n",
      "** 1000 steps\n",
      "Detection accuracy: 1.0\n",
      "Ratio: 1.4887135028839111\n",
      "\n",
      "\n",
      "*  Base_id35_reference\n",
      "** 200 steps\n",
      "Detection accuracy: 0.004000000189989805\n",
      "Ratio: -0.4277395009994507\n",
      "** 500 steps\n",
      "Detection accuracy: 0.004000000189989805\n",
      "Ratio: -2.3391990661621094\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.006000000052154064\n",
      "Ratio: -0.822628915309906\n",
      "\n",
      "\n",
      "*  Critical_id10_numbers_replaced\n",
      "** 200 steps\n",
      "Detection accuracy: 0.35499998927116394\n",
      "Ratio: 0.04136919602751732\n",
      "** 500 steps\n",
      "Detection accuracy: 0.35600000619888306\n",
      "Ratio: 0.05029292777180672\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.3529999852180481\n",
      "Ratio: 0.05777598172426224\n",
      "\n",
      "\n",
      "*  Critical_id11_gender\n",
      "** 200 steps\n",
      "Detection accuracy: 0.11299999803304672\n",
      "Ratio: 0.017647121101617813\n",
      "** 500 steps\n",
      "Detection accuracy: 0.1120000034570694\n",
      "Ratio: 0.020514825358986855\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.11100000143051147\n",
      "Ratio: 0.02771994099020958\n",
      "\n",
      "\n",
      "*  Critical_id20_shuffled\n",
      "** 200 steps\n",
      "Detection accuracy: 0.824999988079071\n",
      "Ratio: 0.02792607992887497\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7760000228881836\n",
      "Ratio: 0.08573414385318756\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.7689999938011169\n",
      "Ratio: 0.041715655475854874\n",
      "\n",
      "\n",
      "*  Critical_id21_adj_adv_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.7990000247955322\n",
      "Ratio: 0.05248274654150009\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7649999856948853\n",
      "Ratio: 0.10707945376634598\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.7450000047683716\n",
      "Ratio: 0.08023127913475037\n",
      "\n",
      "\n",
      "*  Critical_id22_verb_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.824999988079071\n",
      "Ratio: 0.0649241954088211\n",
      "** 500 steps\n",
      "Detection accuracy: 0.8240000009536743\n",
      "Ratio: 0.12100819498300552\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.8140000104904175\n",
      "Ratio: 0.10033886134624481\n",
      "\n",
      "\n",
      "*  Critical_id23_noun_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.8730000257492065\n",
      "Ratio: 0.08818838000297546\n",
      "** 500 steps\n",
      "Detection accuracy: 0.8629999756813049\n",
      "Ratio: 0.1303882598876953\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.8460000157356262\n",
      "Ratio: 0.12425924837589264\n",
      "\n",
      "\n",
      "*  Critical_id24_subj_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.8479999899864197\n",
      "Ratio: 0.09495244920253754\n",
      "** 500 steps\n",
      "Detection accuracy: 0.8240000009536743\n",
      "Ratio: 0.13327187299728394\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.8069999814033508\n",
      "Ratio: 0.13750548660755157\n",
      "\n",
      "\n",
      "*  Critical_id25_ne_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.6520000100135803\n",
      "Ratio: 0.09975600242614746\n",
      "** 500 steps\n",
      "Detection accuracy: 0.6430000066757202\n",
      "Ratio: 0.10609938949346542\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.6359999775886536\n",
      "Ratio: 0.14053437113761902\n",
      "\n",
      "\n",
      "*  Critical_id4_codemix\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9850000143051147\n",
      "Ratio: 0.3310621678829193\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9850000143051147\n",
      "Ratio: 0.4514833092689514\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9850000143051147\n",
      "Ratio: 0.5139873623847961\n",
      "\n",
      "\n",
      "*  Critical_id6_addition\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9089999794960022\n",
      "Ratio: 0.06941764056682587\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9010000228881836\n",
      "Ratio: 0.07647654414176941\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.8840000033378601\n",
      "Ratio: 0.12198741734027863\n",
      "\n",
      "\n",
      "*  Critical_id7_antonym\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9330000281333923\n",
      "Ratio: 0.15012811124324799\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9279999732971191\n",
      "Ratio: 0.06448489427566528\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9290000200271606\n",
      "Ratio: 0.25258946418762207\n",
      "\n",
      "\n",
      "*  Critical_id8_negation\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9810000061988831\n",
      "Ratio: 0.3323467969894409\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9800000190734863\n",
      "Ratio: 0.5808181166648865\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9800000190734863\n",
      "Ratio: 0.613548994064331\n",
      "\n",
      "\n",
      "*  Critical_id9_ne_replaced\n",
      "** 200 steps\n",
      "Detection accuracy: 0.6779999732971191\n",
      "Ratio: 0.22827273607254028\n",
      "** 500 steps\n",
      "Detection accuracy: 0.6769999861717224\n",
      "Ratio: 0.25636348128318787\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.6779999732971191\n",
      "Ratio: 0.34453457593917847\n",
      "\n",
      "\n",
      "*  Major_id17_tense\n",
      "** 200 steps\n",
      "Detection accuracy: 0.7979999780654907\n",
      "Ratio: 0.025345340371131897\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7409999966621399\n",
      "Ratio: 0.038158174604177475\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.7129999995231628\n",
      "Ratio: 0.03349374979734421\n",
      "\n",
      "\n",
      "*  Major_id18_aspect\n",
      "** 200 steps\n",
      "Detection accuracy: 0.8090000152587891\n",
      "Ratio: 0.0219107698649168\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7680000066757202\n",
      "Ratio: 0.013357811607420444\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.6990000009536743\n",
      "Ratio: 0.01953147165477276\n",
      "\n",
      "\n",
      "*  Major_id19_question\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9570000171661377\n",
      "Ratio: 0.1193401888012886\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9549999833106995\n",
      "Ratio: 0.29114753007888794\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9539999961853027\n",
      "Ratio: 0.19261492788791656\n",
      "\n",
      "\n",
      "*  Major_id3_hypernym\n",
      "** 200 steps\n",
      "Detection accuracy: 0.7929999828338623\n",
      "Ratio: 0.08010780066251755\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7879999876022339\n",
      "Ratio: 0.036851875483989716\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.7820000052452087\n",
      "Ratio: 0.10822664946317673\n",
      "\n",
      "\n",
      "*  Major_id5_pp_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.7850000262260437\n",
      "Ratio: 0.11825273931026459\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7480000257492065\n",
      "Ratio: 0.11236540973186493\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.722000002861023\n",
      "Ratio: 0.1372186541557312\n",
      "\n",
      "\n",
      "*  Minor_id12_conj_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.3490000069141388\n",
      "Ratio: 0.010774530470371246\n",
      "** 500 steps\n",
      "Detection accuracy: 0.3109999895095825\n",
      "Ratio: 0.05446827411651611\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.3050000071525574\n",
      "Ratio: 0.016507308930158615\n",
      "\n",
      "\n",
      "*  Minor_id13_pos_shift\n",
      "** 200 steps\n",
      "Detection accuracy: 0.8539999723434448\n",
      "Ratio: 0.05325428396463394\n",
      "** 500 steps\n",
      "Detection accuracy: 0.8410000205039978\n",
      "Ratio: 0.07854799181222916\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.843999981880188\n",
      "Ratio: 0.06783842295408249\n",
      "\n",
      "\n",
      "*  Minor_id14_word_swap\n",
      "** 200 steps\n",
      "Detection accuracy: 0.5130000114440918\n",
      "Ratio: -0.00012433077790774405\n",
      "** 500 steps\n",
      "Detection accuracy: 0.5070000290870667\n",
      "Ratio: 0.007902491837739944\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.5080000162124634\n",
      "Ratio: -0.0005005255807191133\n",
      "\n",
      "\n",
      "*  Minor_id15_case\n",
      "** 200 steps\n",
      "Detection accuracy: 0.28200000524520874\n",
      "Ratio: 0.013790613040328026\n",
      "** 500 steps\n",
      "Detection accuracy: 0.28200000524520874\n",
      "Ratio: 0.0062437462620437145\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.28299999237060547\n",
      "Ratio: 0.023150013759732246\n",
      "\n",
      "\n",
      "*  Minor_id16_function_word\n",
      "** 200 steps\n",
      "Detection accuracy: 0.7289999723434448\n",
      "Ratio: 0.024314627051353455\n",
      "** 500 steps\n",
      "Detection accuracy: 0.671999990940094\n",
      "Ratio: 6.228752317838371e-05\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.6299999952316284\n",
      "Ratio: 0.04178962484002113\n",
      "\n",
      "\n",
      "*  Minor_id1_repeat2\n",
      "** 200 steps\n",
      "Detection accuracy: 0.609000027179718\n",
      "Ratio: 0.007499481551349163\n",
      "** 500 steps\n",
      "Detection accuracy: 0.6700000166893005\n",
      "Ratio: -0.022637929767370224\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.625\n",
      "Ratio: 0.013722133822739124\n",
      "\n",
      "\n",
      "*  Minor_id26_misspelled\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9800000190734863\n",
      "Ratio: 0.17759767174720764\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9760000109672546\n",
      "Ratio: 0.24879902601242065\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9710000157356262\n",
      "Ratio: 0.29564163088798523\n",
      "\n",
      "\n",
      "*  Minor_id27_char_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9599999785423279\n",
      "Ratio: 0.15198662877082825\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9570000171661377\n",
      "Ratio: 0.23384971916675568\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.949999988079071\n",
      "Ratio: 0.2449532002210617\n",
      "\n",
      "\n",
      "*  Minor_id28_final_punc_removed\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9089999794960022\n",
      "Ratio: 0.03551032021641731\n",
      "** 500 steps\n",
      "Detection accuracy: 0.8899999856948853\n",
      "Ratio: 0.08423008024692535\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.9039999842643738\n",
      "Ratio: 0.06387084722518921\n",
      "\n",
      "\n",
      "*  Minor_id29_punc_addition\n",
      "** 200 steps\n",
      "Detection accuracy: 0.9639999866485596\n",
      "Ratio: 0.042577896267175674\n",
      "** 500 steps\n",
      "Detection accuracy: 0.9610000252723694\n",
      "Ratio: 0.16897951066493988\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.953000009059906\n",
      "Ratio: 0.0738653689622879\n",
      "\n",
      "\n",
      "*  Minor_id2_repeat4\n",
      "** 200 steps\n",
      "Detection accuracy: 0.7120000123977661\n",
      "Ratio: 0.025973904877901077\n",
      "** 500 steps\n",
      "Detection accuracy: 0.7429999709129333\n",
      "Ratio: -0.046116676181554794\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.6980000138282776\n",
      "Ratio: 0.03638901934027672\n",
      "\n",
      "\n",
      "*  Minor_id30_tokenized\n",
      "** 200 steps\n",
      "Detection accuracy: 0.020999999716877937\n",
      "Ratio: 0.0011340848868712783\n",
      "** 500 steps\n",
      "Detection accuracy: 0.019999999552965164\n",
      "Ratio: 0.001371231279335916\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.019999999552965164\n",
      "Ratio: 0.0018840759294107556\n",
      "\n",
      "\n",
      "*  Minor_id31_full_lower\n",
      "** 200 steps\n",
      "Detection accuracy: 0.0\n",
      "Ratio: 0.0\n",
      "** 500 steps\n",
      "Detection accuracy: 0.0\n",
      "Ratio: 0.0\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.0\n",
      "Ratio: 0.0\n",
      "\n",
      "\n",
      "*  Minor_id32_first_lower\n",
      "** 200 steps\n",
      "Detection accuracy: 0.0020000000949949026\n",
      "Ratio: 1.8710947188083082e-05\n",
      "** 500 steps\n",
      "Detection accuracy: 0.0020000000949949026\n",
      "Ratio: 3.610430576372892e-05\n",
      "** 1000 steps\n",
      "Detection accuracy: 0.0020000000949949026\n",
      "Ratio: 4.099127181689255e-05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "def demetr_accuracy_bleurt(dataset: pd.DataFrame, bleurt_scorer:BleurtScorer) -> (float, np.array, np.array):\n",
    "    t_scores = torch.tensor(bleurt_scorer.score(references=dataset.eng_sent, candidates=dataset.mt_sent))\n",
    "    hat_scores = torch.tensor(bleurt_scorer.score(references=dataset.eng_sent, candidates=dataset.pert_sent))\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores\n",
    "\n",
    "\n",
    "def demetr_ratio_bleurt(dataset: pd.DataFrame, bleurt_scorer:BleurtScorer) -> float:\n",
    "    acc, t_scores, hat_scores = demetr_accuracy_bleurt(dataset, bleurt_scorer)\n",
    "    print(f\"Detection accuracy: {acc}\")\n",
    "    empty_scores = torch.tensor(bleurt_scorer.score(references=dataset.eng_sent, candidates=[\".\"] * len(dataset)))\n",
    "    ratio = (t_scores - hat_scores) / (t_scores - empty_scores)\n",
    "    ratio = sum(ratio) / len(dataset)\n",
    "    print(f\"Ratio: {ratio}\")\n",
    "    return ratio.item()\n",
    "\n",
    "\n",
    "def eval_models_on_dataset_bleurt(dataset: pd.DataFrame) -> dict:\n",
    "    dataset_scores = {}\n",
    "    print(\"** 200 steps\")\n",
    "    dataset_scores[\"model_200\"] = demetr_ratio_bleurt(dataset, bleurt_scorer_ft_200)\n",
    "    print(\"** 500 steps\")\n",
    "    dataset_scores[\"model_500\"] = demetr_ratio_bleurt(dataset, bleurt_scorer_ft_500)\n",
    "    print(\"** 1000 steps\")\n",
    "    dataset_scores[\"model_1000\"] = demetr_ratio_bleurt(dataset, bleurt_scorer_ft_1000)\n",
    "    return dataset_scores\n",
    "    #print(\"** Fine-tuned model\")\n",
    "    #return demetr_ratio_bleurt(dataset, bleurt_scorer_ft)\n",
    "\n",
    "demetr_scores = {}\n",
    "for pert_name, pert_data in perturbation_datasets.items():\n",
    "    print(\"* \", pert_name.capitalize())\n",
    "    dem_rat = eval_models_on_dataset_bleurt(pert_data)\n",
    "    demetr_scores[pert_name] = dem_rat\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "{'base_id33_empty': None,\n 'base_id33_shuffle_trans': None,\n 'base_id35_reference': None,\n 'critical_id10_numbers_replaced': None,\n 'critical_id11_gender': None,\n 'critical_id20_shuffled': None,\n 'critical_id21_adj_adv_removed': None,\n 'critical_id22_verb_removed': None,\n 'critical_id23_noun_removed': None,\n 'critical_id24_subj_removed': None,\n 'critical_id25_ne_removed': None,\n 'critical_id4_codemix': None,\n 'critical_id6_addition': None,\n 'critical_id7_antonym': None,\n 'critical_id8_negation': None,\n 'critical_id9_ne_replaced': None,\n 'major_id17_tense': None,\n 'major_id18_aspect': None,\n 'major_id19_question': None,\n 'major_id3_hypernym': None,\n 'major_id5_pp_removed': None,\n 'minor_id12_conj_removed': None,\n 'minor_id13_pos_shift': None,\n 'minor_id14_word_swap': None,\n 'minor_id15_case': None,\n 'minor_id16_function_word': None,\n 'minor_id1_repeat2': None,\n 'minor_id26_misspelled': None,\n 'minor_id27_char_removed': None,\n 'minor_id28_final_punc_removed': None,\n 'minor_id29_punc_addition': None,\n 'minor_id2_repeat4': None,\n 'minor_id30_tokenized': None,\n 'minor_id31_full_lower': None,\n 'minor_id32_first_lower': None}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demetr_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eval on DEMETR data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_demetr_dataset(data_path:str) -> pd.DataFrame:\n",
    "    df:pd.DataFrame = pd.read_json(demetr_data_path + data_path)\n",
    "    return df\n",
    "\n",
    "demetr_data_path = \"demetr-main/dataset/\"\n",
    "perturbation_datasets = {\n",
    "    \"negation\": load_demetr_dataset(\"critical_id8_negation.json\"),\n",
    "    \"antonym\": load_demetr_dataset(\"critical_id7_antonym.json\"),\n",
    "    \"baseline_shuffle\": load_demetr_dataset(\"base_id33_shuffle_trans.json\"),\n",
    "    \"verb removed\": load_demetr_dataset(\"critical_id22_verb_removed.json\"),\n",
    "    \"hypernym\": load_demetr_dataset(\"major_id3_hypernym.json\"),\n",
    "    #\"gender\": load_demetr_dataset(\"critical_id11_gender.json\"),\n",
    "    #\"repeat4\": load_demetr_dataset(\"minor_id2_repeat4.json\")\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "perturbation_datasets = {}\n",
    "for filename in os.listdir(demetr_data_path):\n",
    "    perturbation_datasets[filename.replace(\".json\", \"\")] = load_demetr_dataset(filename)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\"\"\"def demetr_accuracy_sent_transform(dataset: pd.DataFrame, model:SentenceTransformer, score_function) -> (float, np.array, np.array):\n",
    "    t_scores = score_function(dataset.eng_sent, dataset.mt_sent, model)\n",
    "    hat_scores = score_function(dataset.eng_sent, dataset.pert_sent, model)\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores\n",
    "\"\"\"\n",
    "batch_size = 16\n",
    "def batchwise_score(sents1, sents2, model, score_function):\n",
    "    scores = []\n",
    "    for i in range(0, len(sents1), batch_size):\n",
    "        scores.append(score_function(sents1[i:i+batch_size], sents2[i:i+batch_size], model))\n",
    "    return scores\n",
    "\n",
    "def demetr_accuracy(dataset: pd.DataFrame, model, score_function) -> (float, np.array, np.array):\n",
    "    t_scores = batchwise_score(dataset.eng_sent, dataset.mt_sent, model, score_function)\n",
    "    hat_scores = batchwise_score(dataset.eng_sent, dataset.pert_sent, model, score_function)\n",
    "    return sum(torch.greater(t_scores, hat_scores)) / len(dataset), t_scores, hat_scores\n",
    "\n",
    "#def demetr_ratio(dataset: pd.DataFrame, model:SentenceTransformer, score_function) -> None:\n",
    "def demetr_ratio(dataset: pd.DataFrame, model, score_function) -> None:\n",
    "    acc, t_scores, hat_scores = demetr_accuracy(dataset, model, score_function)\n",
    "    print(f\"Detection accuracy: {acc}\")\n",
    "    empty_scores = score_function(dataset.eng_sent, [\"\"] * len(dataset), model)\n",
    "    ratio = (t_scores - hat_scores) / (t_scores - empty_scores)\n",
    "    ratio = sum(ratio) / len(dataset)\n",
    "    print(f\"Ratio: {ratio}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*  Negation\n",
      "** Base model\n"
     ]
    }
   ],
   "source": [
    "def eval_models_on_dataset(dataset:pd.DataFrame, score_function) -> None:\n",
    "    print(\"** Base model\")\n",
    "    #demetr_ratio(dataset, base_model, score_function)\n",
    "    demetr_ratio(dataset, model, score_function)\n",
    "    #print(\"** Fine-tuned model\")\n",
    "    #demetr_ratio(dataset, finetuned_model, score_function)\n",
    "\n",
    "for pert_name, pert_data in perturbation_datasets.items():\n",
    "    print(\"* \", pert_name.capitalize())\n",
    "    eval_models_on_dataset(pert_data, cos_score_batched)\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Semsimilarity choose right antonym"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       idx  label                      input  \\\n0        0      2            You're not fat.   \n1        1      2            You're not fat.   \n2        2      2          It's not healthy.   \n3        3      2     That's not acceptable.   \n4        4      2            I'm not guilty.   \n...    ...    ...                        ...   \n3147  3147      2     I know it is possible.   \n3148  3148      2     I know it is possible.   \n3149  3149      2  No, it's a good idea, no.   \n3150  3150      2  No, it's a good idea, no.   \n3151  3151      2               He's asleep.   \n\n                                              sentences  \n0         [You're not thin., You're fat., You're thin.]  \n1     [You're not nonfat., You're fat., You're nonfat.]  \n2     [It's not unhealthy., It's healthy., It's unhe...  \n3     [That's not unacceptable., That's acceptable.,...  \n4       [I'm not innocent., I'm guilty., I'm innocent.]  \n...                                                 ...  \n3147  [I know it is impossible., I know it is not po...  \n3148  [I know it is actual., I know it is not possib...  \n3149  [No, it's a bad idea, no., No, it's not a good...  \n3150  [No, it's an evil idea, no., No, it's not a go...  \n3151   [He's awake., He's not asleep., He's not awake.]  \n\n[3152 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>label</th>\n      <th>input</th>\n      <th>sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>You're not fat.</td>\n      <td>[You're not thin., You're fat., You're thin.]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>You're not fat.</td>\n      <td>[You're not nonfat., You're fat., You're nonfat.]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>It's not healthy.</td>\n      <td>[It's not unhealthy., It's healthy., It's unhe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2</td>\n      <td>That's not acceptable.</td>\n      <td>[That's not unacceptable., That's acceptable.,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2</td>\n      <td>I'm not guilty.</td>\n      <td>[I'm not innocent., I'm guilty., I'm innocent.]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3147</th>\n      <td>3147</td>\n      <td>2</td>\n      <td>I know it is possible.</td>\n      <td>[I know it is impossible., I know it is not po...</td>\n    </tr>\n    <tr>\n      <th>3148</th>\n      <td>3148</td>\n      <td>2</td>\n      <td>I know it is possible.</td>\n      <td>[I know it is actual., I know it is not possib...</td>\n    </tr>\n    <tr>\n      <th>3149</th>\n      <td>3149</td>\n      <td>2</td>\n      <td>No, it's a good idea, no.</td>\n      <td>[No, it's a bad idea, no., No, it's not a good...</td>\n    </tr>\n    <tr>\n      <th>3150</th>\n      <td>3150</td>\n      <td>2</td>\n      <td>No, it's a good idea, no.</td>\n      <td>[No, it's an evil idea, no., No, it's not a go...</td>\n    </tr>\n    <tr>\n      <th>3151</th>\n      <td>3151</td>\n      <td>2</td>\n      <td>He's asleep.</td>\n      <td>[He's awake., He's not asleep., He's not awake.]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3152 rows  4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open(\"SemAntoNeg_v1.0.json\") as file_obj:\n",
    "    data_list = []\n",
    "    for line in file_obj:\n",
    "        data_list.append(json.loads(line))\n",
    "semsim = pd.DataFrame(data_list)\n",
    "semsim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3152/3152 [06:18<00:00,  8.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "num_samples = 3\n",
    "base_prefs = []\n",
    "ft_prefs = []\n",
    "for inp, sents in tqdm(zip(semsim.input.values, semsim.sentences.values), total=len(semsim)):\n",
    "  #base_scores = cos_score_batched([inp] * 3, sents, base_model)\n",
    "  #base_scores = torch.tensor(bleurt_scorer_orig.score(references=[inp] * 3, candidates=sents))\n",
    "  #base_prefs.append(torch.argmax(base_scores).item())\n",
    "  #ft_scores = cos_score_batched([inp] * 3, sents, finetuned_model)\n",
    "  ft_scores = torch.tensor(bleurt_scorer_ft.score(references=[inp] * 3, candidates=sents))\n",
    "  ft_prefs.append(torch.argmax(ft_scores).item())\n",
    "  #print(\"Base model score\", cos_score_batched([inp] * 3, sents, base_model))\n",
    "  #print(\"Fine-tuned model score\", cos_score_batched([inp] * 3, sents, finetuned_model))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model accuracy:  0.015545685279187817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "labels = semsim.label.values[:len(ft_prefs)]\n",
    "#print(\"Base model accuracy: \", accuracy_score(labels, base_prefs))\n",
    "print(\"Fine-tuned model accuracy: \", accuracy_score(labels, ft_prefs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EvalEval perturbations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Perturbations  annotator 1  annotator 2  \\\n0                        Remove punctuation            0            2   \n1                    Spelling mistake/typos            2            2   \n2                  Missing (nltk) stopwords            4            5   \n3                 Subject-verb disagreement            4            2   \n4                            Jumbling words           10            9   \n5                          Adding Negations            9           10   \n6                      Change number values            6           10   \n7                              Change names            7           10   \n8                   Removing named entities            4            7   \n9                    Retain only stop words            9           10   \n10  Removing adjectives that precede a noun            2            2   \n11                               Drop words            5            8   \n12                  Replacing with antonyms           10           10   \n13                                 Hyponyms            5           10   \n14                           repeat Phrases            6            3   \n15                           add extra text            4            8   \n16                             contractions            0            0   \n17                               Expansions            0            0   \n18                                num2words            0            0   \n19                  Replacing with synonyms            0            0   \n20                      Alternate reference            0            0   \n\n    annotator 3  annotator 4  annotator 5  annotator 6  annotator 7  \\\n0             1            1          1.0            1            0   \n1             4            3          2.0            4            1   \n2             2            3          3.0            1            4   \n3             1            2          2.0            1            1   \n4             5           10          7.0            8           10   \n5            10           10          9.5           10           10   \n6             9            8          8.0           10            9   \n7             7            8          9.0            6            5   \n8             2            5          7.0            2            3   \n9            10           10          9.5           10           10   \n10            1            1          3.0            2            2   \n11            4            5          7.0            5            4   \n12            9           10          9.5           10           10   \n13            5            8          8.0            5            5   \n14            2            5          4.0            6            4   \n15            4            8          5.0            7            4   \n16            0            0          0.0            0            0   \n17            0            0          0.0            0            0   \n18            0            0          0.0            0            0   \n19            1            0          0.0            0            0   \n20            0            0          0.0            0            0   \n\n    annotator 8  annotator 9  annotator 10  annotator 11  annotator 12  \\\n0             2            3             1             0             2   \n1             4            2             2             4             3   \n2             5            5             2             5             4   \n3             4            1             1             3             1   \n4             6            6             5            10             8   \n5             7           10            10            10             8   \n6             4           10             9            10             6   \n7             7           10             8            10             5   \n8             6            7             3            10             5   \n9            10           10            10            10             9   \n10            3            4             3             8             0   \n11            6            7             5            10             5   \n12            7           10            10            10             6   \n13            4           10             5            10             1   \n14            7            0             7             3             5   \n15            7            7             7             8             4   \n16            0            0             0             0             0   \n17            0            0             0             0             0   \n18            0            0             0             0             0   \n19            0            3             1             0             0   \n20            0            0             0             0             0   \n\n    annotator 13  annotator 14  annotator 15  \n0              1             0             0  \n1              1             2             1  \n2              3             3             0  \n3              4             3             0  \n4              9             9             4  \n5             10             8            10  \n6             10             8             9  \n7             10             8             6  \n8              8             8             0  \n9             10             9            10  \n10             2             0             1  \n11             8             8             5  \n12            10             8            10  \n13            10             8             2  \n14             5             3             2  \n15             8             5             5  \n16             0             0             0  \n17             0             0             0  \n18             0             0             0  \n19             0             0             0  \n20             0             0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Perturbations</th>\n      <th>annotator 1</th>\n      <th>annotator 2</th>\n      <th>annotator 3</th>\n      <th>annotator 4</th>\n      <th>annotator 5</th>\n      <th>annotator 6</th>\n      <th>annotator 7</th>\n      <th>annotator 8</th>\n      <th>annotator 9</th>\n      <th>annotator 10</th>\n      <th>annotator 11</th>\n      <th>annotator 12</th>\n      <th>annotator 13</th>\n      <th>annotator 14</th>\n      <th>annotator 15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Remove punctuation</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Spelling mistake/typos</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Missing (nltk) stopwords</td>\n      <td>4</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Subject-verb disagreement</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jumbling words</td>\n      <td>10</td>\n      <td>9</td>\n      <td>5</td>\n      <td>10</td>\n      <td>7.0</td>\n      <td>8</td>\n      <td>10</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>10</td>\n      <td>8</td>\n      <td>9</td>\n      <td>9</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Adding Negations</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9.5</td>\n      <td>10</td>\n      <td>10</td>\n      <td>7</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Change number values</td>\n      <td>6</td>\n      <td>10</td>\n      <td>9</td>\n      <td>8</td>\n      <td>8.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Change names</td>\n      <td>7</td>\n      <td>10</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n      <td>5</td>\n      <td>10</td>\n      <td>8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Removing named entities</td>\n      <td>4</td>\n      <td>7</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>7</td>\n      <td>3</td>\n      <td>10</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Retain only stop words</td>\n      <td>9</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9.5</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Removing adjectives that precede a noun</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Drop words</td>\n      <td>5</td>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7.0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>5</td>\n      <td>10</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Replacing with antonyms</td>\n      <td>10</td>\n      <td>10</td>\n      <td>9</td>\n      <td>10</td>\n      <td>9.5</td>\n      <td>10</td>\n      <td>10</td>\n      <td>7</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Hyponyms</td>\n      <td>5</td>\n      <td>10</td>\n      <td>5</td>\n      <td>8</td>\n      <td>8.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>4</td>\n      <td>10</td>\n      <td>5</td>\n      <td>10</td>\n      <td>1</td>\n      <td>10</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>repeat Phrases</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>add extra text</td>\n      <td>4</td>\n      <td>8</td>\n      <td>4</td>\n      <td>8</td>\n      <td>5.0</td>\n      <td>7</td>\n      <td>4</td>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>8</td>\n      <td>4</td>\n      <td>8</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>contractions</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Expansions</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>num2words</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Replacing with synonyms</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Alternate reference</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "human_score_mt = pd.read_csv(\"EvalEvalMain/data/MachineTranslation.csv\")\n",
    "human_score_mt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}